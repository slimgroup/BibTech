% This file was created with JabRef 2.6.
% Encoding: MacRoman

@CONFERENCE{erlangga08SINBADimf,
  author = {Yogi A. Erlangga and K. Vuik and K. Oosterlee and D. Riyanti and
        R. Nabben},
  title = {Iterative methods for 2D/3D Helmholtz operator},
  booktitle = {SINBAD 2008},
  year = {2008},
  abstract = {We present an iterative method for solving the 2D/3D Helmholtz equation.
        The method is mainly based on a Krylov method, preconditioned by
        a special operator which represents a damped Helmholtz operator.
        The discretization of the preconditioning operator is then solved
        by one multigrid sweep. It can be shown that while the spectrum is
        bounded above by one, the smallest eigenvalue of the preconditioned
        system is of order $k^{-1}$. In this situation, the convergence of
        a Krylov method will be proportional to the frequency of the problem.
        Further convergence acceleration can be achieved if eigenvalues of
        order $k^{-1}$ are projected from the spectrum. This can be done
        by a projection operator, similar to but more stable than deflation.
        This projection operator has been the core of a new multilevel method,
        called multilevel Krylov method, proposed by Erlangga and Nabben
        only recently. Putting the preconditioned Helmholtz operator in this
        setting, a convergence which is independent of frequency can be obtained.},
  keywords = {Presentation, SINBAD, SLIM},
  url = {http://slim.eos.ubc.ca/SINBAD2008/Program_files/SINBAD2008_Erlangga_Ite.pdf}}


@ARTICLE{berkhout97eom,
  author = {A. J. Berkhout and D. J. Verschuur},
  title = {Estimation of multiple scattering by iterative inversion, Part {I}:
	Theoretical considerations},
  journal = {Geophysics},
  year = {1997},
  volume = {62},
  pages = {1586-1595},
  number = {5},
  abstract = {A review has been given of the surface-related multiple problem by
	making use of the so-called feedback model. From the resulting equations
	it has been concluded that the proposed solution does not require
	any properties of the subsurface. However, source-detector and reflectivity
	properties of the surface need be specified. Those properties have
	been quantified in a surface operator and this operator is estimated
	as part of the multiple removal problem. The surface-related multiple
	removal algorithm has been formulated in terms of a Neumann series
	and in terms of an iterative equation. The Neumann formulation requires
	a nonlinear optimization process for the surface operator; while
	the iterative formulation needs a number of linear optimizations.
	The iterative formulation also has the advantage that it can be integrated
	easily with another multiple removal method. An algorithm for the
	removal of internal multiples has been proposed as well. This algorithm
	is an extension of the surface-related method. Removal of internal
	multiples requires knowledge of the macro velocity model between
	the surface and the upper boundary of the multiple generating layer.
	In part II (also published in this issue) the success of the proposed
	algorithms has been demonstrated on numerical experiments and field
	data examples. {\copyright}1997 Society of Exploration Geophysicists},
  bdsk-url-1 = {http://library.seg.org/doi/abs/10.1190/1.1444261},
  bdsk-url-2 = {http://dx.doi.org/10.1190/1.1444261},
  date-added = {2008-05-07 18:38:50 -0700},
  date-modified = {2008-08-14 14:46:15 -0700},
  doi = {10.1190/1.1444261},
  issue = {5},
  keywords = {SRME},
  pdf = {http://library.seg.org/doi/abs/10.1190/1.1444261},
  publisher = {SEG},
  url = {http://library.seg.org/doi/abs/10.1190/1.1444261}
}

@BOOK{biondo063ds,
  title = {3-{D} seismic imaging},
  publisher = {SEG},
  year = {2006},
  author = {B. L. Biondi},
  number = {14},
  series = {Investigations in Geophysics},
  date-added = {2008-05-08 15:25:18 -0700},
  date-modified = {2008-05-20 19:45:00 -0700},
  issue = {14},
  keywords = {imaging}
}

@ARTICLE{cordoba78wpa,
  author = {A. C\'ordoba and C. Fefferman},
  title = {Wave packets and {F}ourier integral operators},
  journal = {Communications in Partial Differential Equations},
  year = {1978},
  volume = {3},
  pages = {979-1005},
  number = {11},
  bdsk-url-1 = {http://dx.doi.org/10.1080/03605307808820083},
  date-added = {2008-05-07 11:53:23 -0700},
  date-modified = {2008-05-20 11:48:08 -0700},
  doi = {10.1080/03605307808820083},
  issue = {11},
  keywords = {wave packets, FIO},
  publisher = {Taylor \& Francis}
}

@PHDTHESIS{candes98rta,
  author = {E. J. Cand\`es},
  title = {Ridgelets: theory and applications},
  school = {Stanford University},
  year = {1998},
  address = {Stanford, CA},
  bdsk-url-1 = {http://www-stat.stanford.edu/%7Ecandes/papers/Thesis.ps.gz},
  date-added = {2008-05-27 18:24:11 -0700},
  date-modified = {2008-05-27 18:26:14 -0700},
  keywords = {ridgelet transform}
}

@ARTICLE{candes05tcr,
  author = {E. J. Cand\`es and L. Demanet},
  title = {The curvelet representation of wave propagators is optimally sparse},
  journal = {Communications on Pure and Applied Mathematics},
  year = {2005},
  volume = {58},
  pages = {1472-1528},
  number = {11},
  abstract = {This paper argues that curvelets provide a powerful tool for representing
	very general linear symmetric systems of hyperbolic differential
	equations. Curvelets are a recently developed multiscale system [10,
	7] in which the elements are highly anisotropic at fine scales, with
	effective support shaped according to the parabolic scaling principle
	width â‰ˆ length^2 at fine scales. We prove that for a wide class
	of linear hyperbolic differential equations, the curvelet representation
	of the solution operator is both optimally sparse and well organized.
	* It is sparse in the sense that the matrix entries decay nearly
	exponentially fast (i.e. faster than any negative polynomial), *
	and well-organized in the sense that the very few nonnegligible entries
	occur near a few shifted diagonals. Indeed, we show that the wave
	group maps each curvelet onto a sum of curvelet-like waveforms whose
	locations and orientations are obtained by following the different
	Hamiltonian flows---hence the diagonal shifts in the curvelet representation.
	A physical interpretation of this result is that curvelets may be
	viewed as coherent waveforms with enough frequency localization so
	that they behave like waves but at the same time, with enough spatial
	localization so that they simultaneously behave like particles. },
  bdsk-url-1 = {http://www-stat.stanford.edu/%7Ecandes/papers/CurveletsWaves.pdf},
  date-added = {2008-05-07 11:10:43 -0700},
  date-modified = {2008-08-14 14:57:23 -0700},
  doi = {10.1002/cpa.20078},
  issue = {11},
  keywords = {curvelet transform, FIO},
  pdf = {http://www-stat.stanford.edu/%7Ecandes/papers/CurveletsWaves.pdf}
}

@ARTICLE{candes06fdc,
  author = {E. J. Cand\`es and L. Demanet and D. L. Donoho and L. Ying},
  title = {Fast discrete curvelet transforms},
  journal = {Multiscale Modeling and Simulation},
  year = {2006},
  volume = {5},
  pages = {861-899},
  number = {3},
  abstract = {This paper describes two digital implementations of a new mathematical
	transform, namely, the second generation curvelet transform [12,
	10] in two and three dimensions. The first digital transformation
	is based on unequally-spaced fast Fourier transforms (USFFT) while
	the second is based on the wrapping of specially selected Fourier
	samples. The two implementations essentially differ by the choice
	of spatial grid used to translate curvelets at each scale and angle.
	Both digital transformations return a table of digital curvelet coefficients
	indexed by a scale parameter, an orientation parameter, and a spatial
	location parameter. And both implementations are fast in the sense
	that they run in O(n^2 log n) flops for n by n Cartesian arrays;
	in addition, they are also invertible, with rapid inversion algorithms
	of about the same complexity. Our digital transformations improve
	upon earlier implementations---based upon the first generation of
	curvelets---in the sense that they are conceptually simpler, faster
	and far less redundant. The software CurveLab, which implements both
	transforms presented in this paper, is available at http://www.curvelet.org.
	},
  bdsk-url-1 = {http://dx.doi.org/10.1137/05064182X},
  bdsk-url-2 = {http://www-stat.stanford.edu/%7Ecandes/papers/FDCT.pdf},
  date-added = {2008-05-06 19:34:41 -0700},
  date-modified = {2008-08-14 14:58:30 -0700},
  doi = {10.1137/05064182X},
  issue = {3},
  keywords = {curvelet transform},
  pdf = {http://www-stat.stanford.edu/%7Ecandes/papers/FDCT.pdf},
  publisher = {SIAM}
}

@INCOLLECTION{candes00cas,
  author = {E. J. Cand\`es and D. L. Donoho},
  title = {Curvelets: a surprisingly effective nonadaptive representation of
	objects with edges},
  booktitle = {Curve and surface fitting},
  publisher = {Vanderbilt University Press},
  year = {2000},
  editor = {A. Cohen, C. Rahut, and L. L. Schumaker},
  pages = {105-120},
  address = {Nashville, TN},
  abstract = {It is widely believed that to efficiently represent an otherwise smooth
	ob ject with discontinuities along edges, one must use an adaptive
	representation that in some sense `tracks' the shape of the discontinuity
	set. This folk-belief --- some would say folk-theorem --- is incorrect.
	At the very least, the possible quantitative advantage of such adaptation
	is vastly smaller than commonly believed. We have recently constructed
	a tight frame of curvelets which provides stable, efficient, and
	near-optimal representation of otherwise smooth ob jects having discontinuities
	along smooth curves. By applying naive thresholding to the curvelet
	transform of such an ob ject, one can form m-term approximations
	with rate of L2 approximation rivaling the rate obtainable by complex
	adaptive schemes which attempt to `track' the discontinuity set.
	In this article we explain the basic issues of efficient m-term approximation,
	the construction of efficient adaptive representation, the construction
	of the curvelet frame, and a crude analysis of the performance of
	curvelet schemes. },
  bdsk-url-1 = {http://www-stat.stanford.edu/%7Ecandes/papers/Curvelet-SMStyle.pdf},
  date-added = {2008-05-26 17:48:55 -0700},
  date-modified = {2008-08-14 15:26:58 -0700},
  keywords = {curvelet transform}
}

@ARTICLE{candes05cct,
  author = {E. J. Cand\`es and D. L. Donoho},
  title = {Continuous curvelet transform: {I.} Resolution of the wavefront set},
  journal = {Applied and Computational Harmonic Analysis},
  year = {2005},
  volume = {19},
  pages = {162-197},
  number = {2},
  month = {September},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.acha.2005.02.003},
  date-added = {2008-05-26 18:21:22 -0700},
  date-modified = {2008-05-26 18:23:57 -0700},
  issue = {2},
  keywords = {curvelet transform}
}

@ARTICLE{candes05cct1,
  author = {E. J. Cand\`es and D. L. Donoho},
  title = {Continuous curvelet transform: {II.} Discretization and frames},
  journal = {Applied and Computational Harmonic Analysis},
  year = {2005},
  volume = {19},
  pages = {198-222},
  number = {2},
  month = {September},
  bdsk-url-1 = {http://dx.doi.org/10.1016/j.acha.2005.02.004},
  date-added = {2008-05-26 18:23:17 -0700},
  date-modified = {2008-05-26 18:24:36 -0700},
  issue = {2},
  keywords = {curvelet transform}
}

@ARTICLE{candes04ntf,
  author = {E. J. Cand\`es and D. L. Donoho},
  title = {New tight frames of curvelets and optimal representations of objects
	with piecewise-{C}$^2$ singularities},
  journal = {Communications on Pure and Applied Mathematics},
  year = {2004},
  volume = {57},
  pages = {219-266},
  number = {2},
  bdsk-url-1 = {http://dx.doi.org/10.1002/cpa.10116},
  bdsk-url-2 = {http://www-stat.stanford.edu/%7Ecandes/papers/CurveEdges.pdf},
  date-added = {2008-05-07 11:47:59 -0700},
  date-modified = {2008-08-14 14:46:59 -0700},
  doi = {10.1002/cpa.10116},
  issue = {2},
  keywords = {curvelet transform},
  pdf = {http://www-stat.stanford.edu/%7Ecandes/papers/CurveEdges.pdf}
}

@ARTICLE{chauris08sdm,
  author = {H. Chauris and T. Nguyen},
  title = {Seismic demigration/migration in the curvelet domain},
  journal = {Geophysics},
  year = {2008},
  volume = {73},
  pages = {S35-S46},
  number = {2},
  abstract = {Curvelets can represent local plane waves. They efficiently decompose
	seismic images and possibly imaging operators. We study how curvelets
	are distorted after demigration followed by migration in a different
	velocity model. We show that for small local velocity perturbations,
	the demigration/migration is reduced to a simple morphing of the
	initial curvelet. The derivation of the expected curvature of the
	curvelets shows that it is easier to sparsify the demigration/migration
	operator than the migration operator. An application on a 2D synthetic
	data set, generated in a smooth heterogeneous velocity model and
	with a complex reflectivity, demonstrates the usefulness of curvelets
	to predict what a migrated image would become in a locally different
	velocity model without the need for remigrating the full input data
	set. Curvelets are thus well suited to study the sensitivity of a
	prestack depth-migrated image with respect to the heterogeneous velocity
	model used for migration. {\copyright}2008 Society of Exploration
	Geophysicists},
  bdsk-url-1 = {http://library.seg.org/doi/abs/10.1190/1.2831933},
  bdsk-url-2 = {http://dx.doi.org/10.1190/1.2831933},
  date-added = {2008-05-07 14:48:33 -0700},
  date-modified = {2008-08-14 14:59:04 -0700},
  doi = {10.1190/1.2831933},
  issue = {2},
  keywords = {curvelet transform, imaging},
  pdf = {http://library.seg.org/doi/abs/10.1190/1.2831933},
  publisher = {SEG}
}

@BOOK{claerbout92esa,
  title = {Earth soundings analysis: processing versus inversion},
  publisher = {Blackwell Scientific Publications},
  year = {1992},
  author = {J. F. Claerbout},
  address = {Boston},
  bdsk-url-1 = {http://sepwww.stanford.edu/sep/prof/pvi.pdf},
  date-added = {2008-05-06 19:27:28 -0700},
  date-modified = {2008-05-07 11:44:19 -0700},
  keywords = {PEF},
  pdf = {http://sepwww.stanford.edu/sep/prof/pvi.pdf}
}

@ARTICLE{claerbout71tau,
  author = {J. F. Claerbout},
  title = {Toward a unified theory of reflector mapping},
  journal = {Geophysics},
  year = {1971},
  volume = {36},
  pages = {467-481},
  number = {3},
  abstract = {Schemes for seismic mapping of reflectors in the presence of an arbitrary
	velocity model, dipping and curved reflectors, diffractions, ghosts,
	surface elevation variations, and multiple reflections are reviewed
	and reduced to a single formula involving up and downgoing waves.
	The mapping formula may be implemented without undue complexity by
	means of difference approximations to the relativistic Schroedinger
	equation. {\copyright}1971 Society of Exploration Geophysicists},
  bdsk-url-1 = {http://library.seg.org/doi/abs/10.1190/1.1440185},
  bdsk-url-2 = {http://dx.doi.org/10.1190/1.1440185},
  date-added = {2008-05-08 14:59:36 -0700},
  date-modified = {2008-08-14 14:59:35 -0700},
  doi = {10.1190/1.1440185},
  issue = {3},
  keywords = {WEM, imaging},
  pdf = {http://library.seg.org/doi/abs/10.1190/1.1440185},
  publisher = {SEG}
}

@ARTICLE{daubechies04ait,
  author = {I. Daubechies and M. Defrise and C. {De Mol}},
  title = {An iterative thresholding algorithm for linear inverse problems with
	a sparsity constraint},
  journal = {Communications on Pure and Applied Mathematics},
  year = {2004},
  volume = {57},
  pages = {1413-1457},
  number = {11},
  abstract = {We consider linear inverse problems where the solution is assumed
	to have a sparse expansion on an arbitrary preassigned orthonormal
	basis. We prove that replacing the usual quadratic regularizing penalties
	by weighted p-penalties on the coefficients of such expansions, with
	1 p 2, still regularizes the problem. Use of such p-penalized problems
	with p < 2 is often advocated when one expects the underlying ideal
	noiseless solution to have a sparse expansion with respect to the
	basis under consideration. To compute the corresponding regularized
	solutions, we analyze an iterative algorithm that amounts to a Landweber
	iteration with thresholding (or nonlinear shrinkage) applied at each
	iteration step. We prove that this algorithm converges in norm. {\copyright}
	2004 Wiley Periodicals, Inc.},
  bdsk-url-1 = {http://dx.doi.org/10.1002/cpa.20042},
  date-added = {2008-05-20 13:58:17 -0700},
  date-modified = {2008-08-14 15:01:17 -0700},
  issue = {11},
  pdf = {http://dx.doi.org/10.1002/cpa.20042},
  refer1 = {10.1002/cpa.20042}
}

@ARTICLE{do2002can,
  author = {M. N. Do and M. Vetterli},
  title = {Contourlets: a new directional multiresolution image representation},
  journal = {Proceedings. 2002 International Conference on Image Processing.},
  year = {2002},
  volume = {1},
  abstract = {We propose a new scheme, named contourlet, that provides a flexible
	multiresolution, local and directional image expansion. The contourlet
	transform is realized efficiently via a double iterated filter bank
	structure. Furthermore, it can be designed to satisfy the anisotropy
	scaling relation for curves, and thus offers a fast and structured
	curvelet-like decomposition. As a result, the contourlet transform
	provides a sparse representation for two-dimensional piecewise smooth
	signals resembling images. Finally, we show some numerical experiments
	demonstrating the potential of contourlets in several image processing
	tasks.},
  bdsk-url-1 = {http://dx.doi.org/10.1109/ICIP.2002.1038034},
  date-added = {2008-05-07 11:58:00 -0700},
  date-modified = {2008-08-14 15:01:55 -0700},
  doi = {10.1109/ICIP.2002.1038034},
  keywords = {contourlet transform}
}

@TECHREPORT{donoho99dct,
  author = {D. L. Donoho and M. R. Duncan},
  title = {Digital curvelet transform: strategy, implementation, and experiments},
  institution = {Stanford Statistics Department},
  year = {1999},
  month = {November},
  bdsk-url-1 = {http://citeseer.ist.psu.edu/rd/44392127,300178,1,0.25,Download/http://citeseer.ist.psu.edu/cache/papers/cs/15527/http:zSzzSzwww-stat.stanford.eduzSz~donohozSzReportszSz1999zSzDCvT.pdf/donoho99digital.pdf},
  date-added = {2008-05-26 17:33:51 -0700},
  date-modified = {2008-05-26 17:35:32 -0700},
  keywords = {curvelet transform}
}

@ARTICLE{douma07los,
  author = {H. Douma and M. V. de Hoop},
  title = {Leading-order seismic imaging using curvelets},
  journal = {Geophysics},
  year = {2007},
  volume = {72},
  pages = {S231-S248},
  number = {6},
  abstract = {Curvelets are plausible candidates for simultaneous compression of
	seismic data, their images, and the imaging operator itself. We show
	that with curvelets, the leading-order approximation (in angular
	frequency, horizontal wavenumber, and migrated location) to common-offset
	(CO) Kirchhoff depth migration becomes a simple transformation of
	coordinates of curvelets in the data, combined with amplitude scaling.
	This transformation is calculated using map migration, which employs
	the local slopes from the curvelet decomposition of the data. Because
	the data can be compressed using curvelets, the transformation needs
	to be calculated for relatively few curvelets only. Numerical examples
	for homogeneous media show that using the leading-order approximation
	only provides a good approximation to CO migration for moderate propagation
	times. As the traveltime increases and rays diverge beyond the spatial
	support of a curvelet; however, the leading-order approximation is
	no longer accurate enough. This shows the need for correction beyond
	leading order, even for homogeneous media. {\copyright}2007 Society
	of Exploration Geophysicists},
  bdsk-url-1 = {http://library.seg.org/doi/abs/10.1190/1.2785047},
  bdsk-url-2 = {http://dx.doi.org/10.1190/1.2785047},
  date-added = {2008-05-07 14:35:47 -0700},
  date-modified = {2008-08-14 15:02:25 -0700},
  doi = {10.1190/1.2785047},
  issue = {6},
  keywords = {curvelet transform, imaging},
  pdf = {http://library.seg.org/doi/abs/10.1190/1.2785047},
  publisher = {SEG}
}

@INCOLLECTION{feichtinger94tap,
  author = {H. G. Feichtinger and K. Grochenig},
  title = {Theory and practice of irregular sampling},
  booktitle = {Wavelets: mathematics and applications},
  publisher = {CRC Press},
  year = {1994},
  editor = {J. J. Benedetto and M. Frazier},
  series = {Studies in Advanced Mathematics},
  chapter = {8},
  pages = {305-363},
  address = {Boca Raton, FL},
  bdsk-url-1 = {http://www.univie.ac.at/nuhag-php/bibtex/open_files/fegr94_fgthpra.pdf},
  date-added = {2008-05-20 17:10:18 -0700},
  date-modified = {2008-05-20 17:24:38 -0700},
  keywords = {sampling},
  pdf = {http://www.univie.ac.at/nuhag-php/bibtex/open_files/fegr94_fgthpra.pdf}
}

@MISC{fenelon08msc,
  author = {Lloyd Fenelon},
  title = {Nonequispaced discrete curvelet transform for seismic data reconstruction},
  howpublished = {BSc thesis, Ecole Nationale Superieure De Physique de Strasbourg},
  month = {August},
  year = {2008},
  abstract = {Physical constraints during seismic acquisitions lead to incomplete
	seismic datasets. Curvelet Reconstruction with Sparsity promoting
	Inversion (CRSI) is one of the most efficient interpolation method
	available to recover complete datasets from data with missing traces.
	The method uses in its definition the curvelet transform which is
	well suited to process seismic data. However, its main shortcoming
	is to not be able to provide an accurate result if the data are acquired
	at irregular positions. This come from the curvelet transform implementation
	which cannot handle this type of data. In this thesis the implementation
	of the curvelet transform is modified to offer the possibility to
	CRSI to give better representation of seismic data for high quality
	seismic imaging. },
  bdsk-url-1 = {http://slim.eos.ubc.ca/Publications/Public/Theses/2008/fenelon08msc.pdf},
  date-added = {2008-09-03 16:18:08 -0700},
  date-modified = {2008-09-03 16:25:10 -0700},
  keywords = {SLIM, BSc},
  pdf = {http://slim.eos.ubc.ca/Publications/Public/Theses/2008/fenelon08msc.pdf}
}

@MISC{fomel07mos,
  author = {S. Fomel and P. Sava},
  title = {{MADAGASCAR}: open-source software package for geophysical data processing
	and reproducible numerical experiments},
  year = {2007},
  abstract = {is an open-source software package for geophysical data analysis and
	reproducible numerical experiments. Its mission is to provide -a
	convenient and powerful environment -a convenient technology transfer
	tool for researchers working with digital image and data processing.
	The technology developed using the Madagascar project management
	system is transferred in the form of recorded processing histories,
	which become "computational recipes" to be verified, exchanged, and
	modified by users of the system.},
  bdsk-url-1 = {http://rsf.sf.net},
  date-added = {2008-06-26 15:31:10 -0700},
  date-modified = {2008-08-14 15:31:44 -0700},
  keywords = {software},
  url = {http://rsf.sf.net}
}

@ARTICLE{guo07osm,
  author = {K. Guo and D. Labate},
  title = {Optimally sparse multidimensional representation using shearlets},
  journal = {Journal of Mathematical Analysis},
  year = {2007},
  volume = {39},
  pages = {298-318},
  number = {1},
  bdsk-url-1 = {http://www4.ncsu.edu/~dlabate/shear_GL.pdf},
  bdsk-url-2 = {http://dx.doi.org/10.1137/060649781},
  date-added = {2008-05-07 12:03:03 -0700},
  date-modified = {2008-05-08 10:28:30 -0700},
  doi = {10.1137/060649781},
  issue = {1},
  keywords = {shearlet transform},
  pdf = {http://www4.ncsu.edu/~dlabate/shear_GL.pdf},
  publisher = {SIAM}
}

@ARTICLE{hampson86ivs,
  author = {D. Hampson},
  title = {Inverse Velocity Stacking for Multiple Elimination},
  journal = {Journal of the Canadian Society of Exploration Geophysicists},
  year = {1986},
  volume = {22},
  pages = {44-45},
  number = {1},
  bdsk-url-1 = {http://209.91.124.56/publications/journal/1986_12/1986_Hampson_D_inverse_velocity_stacking.pdf},
  date-added = {2008-05-06 19:09:45 -0700},
  date-modified = {2008-05-07 11:44:52 -0700},
  issue = {1},
  keywords = {Radon transform},
  pdf = {http://209.91.124.56/publications/journal/1986_12/1986_Hampson_D_inverse_velocity_stacking.pdf},
  publisher = {CSEG}
}

@ARTICLE{hindriks00ro3,
  author = {K. Hindriks and A. J. W. Duijndam},
  title = {Reconstruction of {3-D} seismic signals irregularly sampled along
	two spatial coordinates},
  journal = {Geophysics},
  year = {2000},
  volume = {65},
  pages = {253-263},
  number = {1},
  abstract = {Seismic signals are often irregularly sampled along spatial coordinates,
	leading to suboptimal processing and imaging results. Least-squares
	estimation of Fourier components is used for the reconstruction of
	band-limited seismic signals that are irregularly sampled along two
	spatial coordinates. A simple and efficient diagonal weighting scheme,
	based on the areas surrounding the spatial samples, takes the properties
	of the noise (signal outside the bandwidth) into account in an approximate
	sense. Diagonal stabilization based on the energies of the signal
	and the noise ensures robust estimation. Reconstruction by temporal
	frequency component allows the specification of varying bandwidth
	in two dimensions, depending on the minimum apparent velocity. This
	parameterization improves the reconstruction capability for lower
	temporal frequencies. The shape of the spatial aperture affects the
	method of sampling the Fourier domain. Taking into account this property,
	a larger bandwidth can be recovered. The properties of the least-squares
	estimator allow a very efficient implementation which, when using
	a conjugate gradient algorithm, requires a modest number of 2-D fast
	Fourier transforms per temporal frequency. The method shows signicant
	improvement over the conventionally used binning and stacking method
	on both synthetic and real data. The method can be applied to any
	subset of seismic data with two varying spatial coordinates. {\copyright}2000
	Society of Exploration Geophysicists},
  bdsk-url-1 = {http://link.aip.org/link/?GPY/65/253/1},
  bdsk-url-2 = {http://dx.doi.org/10.1190/1.1444716},
  date-added = {2008-05-20 16:12:37 -0700},
  date-modified = {2008-08-14 15:05:01 -0700},
  doi = {10.1190/1.1444716},
  issue = {1},
  keywords = {reconstruction},
  pdf = {http://link.aip.org/link/?GPY/65/253/1},
  publisher = {SEG}
}

@PHDTHESIS{kunis06nff,
  author = {S. Kunis},
  title = {Nonequispaced {FFT}: generalisation and inversion},
  school = {L\"ubeck university},
  year = {2006},
  bdsk-url-1 = {http://www.analysis.uni-osnabrueck.de/kunis/paper/KunisDiss.pdf},
  date-added = {2008-05-07 18:51:16 -0700},
  date-modified = {2008-05-20 11:49:04 -0700},
  keywords = {NFFT},
  pdf = {http://www.analysis.uni-osnabrueck.de/kunis/paper/KunisDiss.pdf}
}

@ARTICLE{lu07mdf,
  author = {Y. M. Lu and M. N. Do},
  title = {Multidimensional directional filter banks and surfacelets},
  journal = {IEEE Transactions on Image Processing},
  year = {2007},
  volume = {16},
  pages = {918-931},
  number = {4},
  month = {April},
  abstract = {In 1992, Bamberger and Smith proposed the directional filter bank
	(DFB) for an efficient directional decomposition of 2-D signals.
	Due to the nonseparable nature of the system, extending the DFB to
	higher dimensions while still retaining its attractive features is
	a challenging and previously unsolved problem. We propose a new family
	of filter banks, named NDFB, that can achieve the directional decomposition
	of arbitrary N-dimensional (Nges2) signals with a simple and efficient
	tree-structured construction. In 3-D, the ideal passbands of the
	proposed NDFB are rectangular-based pyramids radiating out from the
	origin at different orientations and tiling the entire frequency
	space. The proposed NDFB achieves perfect reconstruction via an iterated
	filter bank with a redundancy factor of N in N-D. The angular resolution
	of the proposed NDFB can be iteratively refined by invoking more
	levels of decomposition through a simple expansion rule. By combining
	the NDFB with a new multiscale pyramid, we propose the surfacelet
	transform, which can be used to efficiently capture and represent
	surface-like singularities in multidimensional data},
  bdsk-url-1 = {http://dx.doi.org/10.1109/TIP.2007.891785},
  date-added = {2008-05-07 12:19:48 -0700},
  date-modified = {2008-08-14 15:05:31 -0700},
  doi = {10.1109/TIP.2007.891785},
  issn = {1057-7149},
  issue = {4},
  keywords = {surfacelet transform},
  publisher = {IEEE}
}

@BOOK{mallat99awt,
  title = {A Wavelet Tour of Signal Processing, Second Edition},
  publisher = {Academic Press},
  year = {1999},
  author = {S. Mallat},
  month = {September},
  date-added = {2008-05-22 16:32:31 -0700},
  date-modified = {2008-05-22 16:33:57 -0700},
  howpublished = {Hardcover},
  isbn = {012466606X},
  keywords = {wavelet transform}
}

@CONFERENCE{morton98fsr,
  author = {S. A. Morton and C. C. Ober},
  title = {Faster shot-record depth migrations using phase encoding},
  booktitle = {SEG Technical Program Expanded Abstracts},
  year = {1998},
  volume = {17},
  number = {1},
  pages = {1131-1134},
  publisher = {SEG},
  bdsk-url-1 = {http://link.aip.org/link/?SGA/17/1131/1},
  bdsk-url-2 = {http://dx.doi.org/10.1190/1.1820088},
  date-added = {2008-05-27 16:44:01 -0700},
  date-modified = {2008-05-27 16:45:21 -0700},
  doi = {10.1190/1.1820088},
  issue = {1},
  pdf = {http://link.aip.org/link/?SGA/17/1131/1}
}

@ARTICLE{paige82lsq,
  author = {C. C. Paige and M. A. Saunders},
  title = {{LSQR}: an algorithm for sparse linear equations and sparse least
	squares},
  journal = {Transactions on Mathematical Software},
  year = {1982},
  volume = {8},
  pages = {43-71},
  number = {1},
  address = {New York, NY, USA},
  bdsk-url-1 = {http://doi.acm.org/10.1145/355984.355989},
  date-added = {2008-05-20 14:00:44 -0700},
  date-modified = {2008-05-20 19:47:37 -0700},
  doi = {http://doi.acm.org/10.1145/355984.355989},
  issn = {0098-3500},
  issue = {1},
  keywords = {LSQR},
  publisher = {ACM}
}

@INCOLLECTION{potts01mst,
  author = {D. Potts and G. Steidl and M. Tasche},
  title = {Fast {F}ourier transforms for nonequispaced data: a tutorial},
  booktitle = {Modern sampling theory: mathematics and applications},
  publisher = {Birkhauser},
  year = {2001},
  editor = {J. J. Benedetto and P. Ferreira},
  chapter = {12},
  pages = {249-274},
  abstract = {In this section, we consider approximate methods for the fast computiation
	of multivariate discrete Fourier transforms for nonequispaced data
	(NDFT) in the time domain and in the frequency domain. In particular,
	we are interested in the approximation error as function of arithmetic
	complexity of the algorithm. We discuss the robustness of NDFT-algorithms
	with respect to roundoff errors and apply NDFT-algorithms for the
	fast computation of Bessel transforms.},
  bdsk-url-1 = {http://www.tu-chemnitz.de/~potts/paper/ndft.pdf},
  date-added = {2008-05-07 18:44:29 -0700},
  date-modified = {2008-08-14 15:28:37 -0700},
  keywords = {NFFT},
  pdf = {http://www.tu-chemnitz.de/~potts/paper/ndft.pdf}
}

@ARTICLE{romero00peo,
  author = {L. A. Romero and D. C. Ghiglia and C. C. Ober and S. A. Morton},
  title = {Phase encoding of shot records in prestack migration},
  journal = {Geophysics},
  year = {2000},
  volume = {65},
  pages = {426-436},
  number = {2},
  abstract = {Frequency-domain shot-record migration can produce higher quality
	images than Kirchhoff migration but typically at a greater cost.
	The computing cost of shot-record migration is the product of the
	number of shots in the survey and the expense of each individual
	migration. Many attempts to reduce this cost have focused on the
	speed of the individual migrations, trying to achieve a better trade-off
	between accuracy and speed. Another approach is to reduce the number
	of migrations. We investigate the simultaneous migration of shot
	records using frequency-domain shot-record migration algorithms.
	The difficulty with this approach is the production of so-called
	crossterms between unrelated shot and receiver wavefields, which
	generate unwanted artifacts or noise in the final image. To reduce
	these artifacts and obtain an image comparable in quality to the
	single-shot-per-migration result, we have introduced a process called
	phase encoding, which shifts or disperses these crossterms. The process
	of phase encoding thus allows one to trade S/N ratio for the speed
	of migrating the entire survey. Several encoding functions and two
	application strategies have been tested. The first strategy, combining
	multiple shots per migration and using each shot only once, reduces
	computation in direct relation to the number of shots combined. The
	second strategy, performing multiple migrations of all the shots
	in the survey, provides a means to reduce the crossterm noise by
	stacking the resulting images. The additional noise in both strategies
	may be tolerated if it is no stronger than the inherent seismic noise
	in the migrated image and if the final image is achieved with less
	cost. {\copyright}2000 Society of Exploration Geophysicists},
  bdsk-url-1 = {http://library.seg.org/doi/abs/10.1190/1.1444737},
  bdsk-url-2 = {http://dx.doi.org/10.1190/1.1444737},
  date-added = {2008-05-27 16:42:50 -0700},
  date-modified = {2008-08-14 15:07:08 -0700},
  doi = {10.1190/1.1444737},
  issue = {2},
  pdf = {http://library.seg.org/doi/abs/10.1190/1.1444737},
  publisher = {SEG}
}

@ARTICLE{sacchi98iae,
  author = {M. D. Sacchi and T. J. Ulrych and C. J. Walker},
  title = {Interpolation and extrapolation using a high-resolution discrete
	{F}ourier transform},
  journal = {IEEE Transactions on Signal Processing},
  year = {1998},
  volume = {46},
  pages = {31-38},
  number = {1},
  abstract = {We present an iterative nonparametric approach to spectral estimation
	that is particularly suitable for estimation of line spectra. This
	approach minimizes a cost function derived from Bayes' theorem. The
	method is suitable for line spectra since a ``long tailed'' distribution
	is used to model the prior distribution of spectral amplitudes. An
	important aspect of this method is that since the data themselves
	are used as constraints, phase information can also be recovered
	and used to extend the data outside the original window. The objective
	function is formulated in terms of hyperpa- rameters that control
	the degree of fit and spectral resolution. Noise rejection can also
	be achieved by truncating the number of iterations. Spectral resolution
	and extrapolation length are controlled by a single parameter. When
	this parameter is large compared with the spectral powers, the algorithm
	leads to zero extrapolation of the data, and the estimated Fourier
	transform yields the periodogram. When the data are sampled at a
	constant rate, the algorithm uses one Levinson recursion per iteration.
	For irregular sampling (unevenly sampled and/or gapped data), the
	algorithm uses one Cholesky decomposition per iteration. The performance
	of the algorithm is illustrated with three different problems that
	frequently arise in geophysical data processing: 1) harmonic retrieval
	from a time series contaminated with noise; 2) linear event detection
	from a finite aperture array of receivers [which, in fact, is an
	extension of 1)], 3) interpolation/extrapolation of gapped data.
	The performance of the algorithm as a spectral estimator is tested
	with the Kay and Marple data set. It is shown that the achieved resolution
	is comparable with parametric methods but with more accurate representation
	of the relative power in the spectral lines. },
  bdsk-url-1 = {http://saig.physics.ualberta.ca/s/sites/default/files/upload/articles/Sacchi_Ulrych_Walker_IEEE_98.pdf},
  date-added = {2008-05-06 19:18:50 -0700},
  date-modified = {2008-08-14 15:08:37 -0700},
  doi = {10.1109/78.651165},
  issue = {1},
  keywords = {Fourier transform, reconstruction},
  pdf = {http://saig.physics.ualberta.ca/s/sites/default/files/upload/articles/Sacchi_Ulrych_Walker_IEEE_98.pdf},
  publisher = {IEEE}
}

@PHDTHESIS{schonewille00phd,
  author = {M. A. Schonewille},
  title = {Fourier reconstruction of irregularly sampled seismic data},
  school = {Delft University of Technology},
  year = {2000},
  address = {Delft, The Netherlands},
  month = {November},
  date-added = {2008-05-06 19:03:35 -0700},
  date-modified = {2008-05-09 14:43:57 -0700},
  keywords = {Fourier transform, reconstruction},
  rating = {0},
  read = {Yes}
}

@ARTICLE{smith98ahs,
  author = {H. Smith},
  title = {A Hardy space for {F}ourier integral operators},
  journal = {Journal of Geometric Analysis},
  year = {1998},
  volume = {8},
  pages = {629-653},
  number = {4},
  date-added = {2008-05-07 12:25:03 -0700},
  date-modified = {2008-08-14 15:09:47 -0700},
  issue = {4},
  keywords = {FIO}
}

@BOOK{snieder93giu,
  title = {Global inversions using normal mode and long-period surface waves},
  publisher = {Chapman and Hall},
  year = {1993},
  author = {R. Snieder},
  date-added = {2008-05-20 17:16:42 -0700},
  date-modified = {2008-05-20 17:19:44 -0700},
  keywords = {sampling}
}

@ARTICLE{spitz91sti,
  author = {S. Spitz},
  title = {Seismic trace interpolation in the {FX} domain},
  journal = {Geophysics},
  year = {1991},
  volume = {56},
  pages = {785-794},
  number = {6},
  abstract = {Interpolation of seismic traces is an effective means of improving
	migration when the data set exhibits spatial aliasing. A major difficulty
	of standard interpolation methods is that they depend on the degree
	of reliability with which the various geological events can be separated.
	In this respect, a multichannel interpolation method is described
	which requires neither a priori knowledge of the directions of lateral
	coherence of the events, nor estimation of these directions. The
	method is based on the fact that linear events present in a section
	made of equally spaced traces may be interpolated exactly, regardless
	of the original spatial interval, without any attempt to determine
	their true dips. The predictability of linear events in the f-x domain
	allows the missing traces to be expressed as the output of a linear
	system, the input of which consists of the recorded traces. The interpolation
	operator is obtained by solving a set of linear equations whose coefficients
	depend only on the spectrum of the spatial prediction filter defined
	by the recorded traces. Synthetic examples show that this method
	is insensitive to random noise and that it correctly handles curvatures
	and lateral amplitude variations. Assessment of the method with a
	real data set shows that the interpolation yields an improved migrated
	section. {\copyright}1991 Society of Exploration Geophysicists},
  bdsk-url-1 = {http://dx.doi.org/10.1190/1.1443096},
  date-added = {2008-05-06 19:29:12 -0700},
  date-modified = {2008-08-14 15:18:16 -0700},
  doi = {10.1190/1.1443096},
  issue = {6},
  keywords = {PEF},
  publisher = {SEG}
}

@ARTICLE{starck02tct,
  author = {J.-L. Starck and E. J. Cand\`es and D. L. Donoho},
  title = {The curvelet transform for image denoising},
  journal = {IEEE Transactions on Image Processing},
  year = {2002},
  volume = {11},
  pages = {670-684},
  number = {6},
  month = {June},
  abstract = {We describe approximate digital implementations of two new mathematical
	transforms, namely, the ridgelet transform and the curvelet transform.
	Our implementations offer exact reconstruction, stability against
	perturbations, ease of implementation, and low computational complexity.
	A central tool is Fourier-domain computation of an approximate digital
	Radon transform. We introduce a very simple interpolation in the
	Fourier space which takes Cartesian samples and yields samples on
	a rectopolar grid, which is a pseudo-polar sampling set based on
	a concentric squares geometry. Despite the crudeness of our interpolation,
	the visual performance is surprisingly good. Our ridgelet transform
	applies to the Radon transform a special overcomplete wavelet pyramid
	whose wavelets have compact support in the frequency domain. Our
	curvelet transform uses our ridgelet transform as a component step,
	and implements curvelet subbands using a filter bank of a&grave;
	trous wavelet filters. Our philosophy throughout is that transforms
	should be overcomplete, rather than critically sampled. We apply
	these digital transforms to the denoising of some standard images
	embedded in white noise. In the tests reported here, simple thresholding
	of the curvelet coefficients is very competitive with "state of the
	art" techniques based on wavelets, including thresholding of decimated
	or undecimated wavelet transforms and also including tree-based Bayesian
	posterior mean methods. Moreover, the curvelet reconstructions exhibit
	higher perceptual quality than wavelet-based reconstructions, offering
	visually sharper images and, in particular, higher quality recovery
	of edges and of faint linear and curvilinear features. Existing theory
	for curvelet and ridgelet transforms suggests that these new approaches
	can outperform wavelet methods in certain image reconstruction problems.
	The empirical results reported here are in encouraging agreement},
  bdsk-url-1 = {http://dx.doi.org/10.1109/TIP.2002.1014998},
  bdsk-url-2 = {http://ieeexplore.ieee.org/iel5/83/21845/01014998.pdf},
  date-added = {2008-05-26 17:38:14 -0700},
  date-modified = {2008-08-14 15:19:16 -0700},
  doi = {10.1109/TIP.2002.1014998},
  issn = {1057-7149},
  issue = {6},
  keywords = {curvelet transform},
  publisher = {IEEE}
}

@ARTICLE{symes07rtm,
  author = {W. W. Symes},
  title = {Reverse time migration with optimal checkpointing},
  journal = {Geophysics},
  year = {2007},
  volume = {72},
  pages = {SM213-SM221},
  number = {5},
  abstract = {Reverse time migration (RTM) requires that fields computed in forward
	time be accessed in reverse order. Such out-of-order access, to recursively
	computed fields, requires that some part of the recursion history
	be stored (checkpointed), with the remainder computed by repeating
	parts of the forward computation. Optimal checkpointing algorithms
	choose checkpoints in such a way that the total storage is minimized
	for a prescribed level of excess computation, or vice versa. Optimal
	checkpointing dramatically reduces the storage required by RTM, compared
	to that needed for nonoptimal implementations, at the price of a
	small increase in computation. This paper describes optimal checkpointing
	in a form which applies both to RTM and other applications of the
	adjoint state method, such as construction of velocity updates from
	prestack wave equation migration. {\copyright}2007 Society of Exploration
	Geophysicists},
  bdsk-url-1 = {http://link.aip.org/link/?GPY/72/SM213/1},
  bdsk-url-2 = {http://dx.doi.org/10.1190/1.2742686},
  date-added = {2008-05-08 14:42:11 -0700},
  date-modified = {2008-08-14 15:19:43 -0700},
  doi = {10.1190/1.2742686},
  issue = {5},
  keywords = {RTM, imaging},
  pdf = {http://link.aip.org/link/?GPY/72/SM213/1},
  publisher = {SEG}
}

@ARTICLE{thorson85vsa,
  author = {J. R. Thorson and J. F. Claerbout},
  title = {Velocity-stack and slant-stack stochastic inversion},
  journal = {Geophysics},
  year = {1985},
  volume = {50},
  pages = {2727-2741},
  number = {12},
  abstract = {Normal moveout (NMO) and stacking, an important step in analysis of
	reflection seismic data, involves summation of seismic data over
	paths represented by a family of hyperbolic curves. This summation
	process is a linear transformation and maps the data into what might
	be called a velocity space: a two-dimensional set of points indexed
	by time and velocity. Examination of data in velocity space is used
	for analysis of subsurface velocities and filtering of undesired
	coherent events (e.g., multiples), but the filtering step is useful
	only if an approximate inverse to the NMO and stack operation is
	available. One way to effect velocity filtering is to use the operator
	LT (defined as NMO and stacking) and its adjoint L as a transform
	pair, but this leads to unacceptable filtered output. Designing a
	better estimated inverse to L than LT is a generalization of the
	inversion problem of computerized tomography: deconvolving out the
	point-spread function after back projection. The inversion process
	is complicated by missing data, because surface seismic data are
	recorded only within a finite spatial aperture on the Earth's surface.
	Our approach to solving the problem of an ill-conditioned or nonunique
	inverse L--1, brought on by missing data, is to design a stochastic
	inverse to L. Starting from a maximum a posteriori (MAP) estimator,
	a system of equations can be set up in which a priori information
	is incorporated into a sparseness measure: the output of the stochastic
	inverse is forced to be locally focused, in order to obtain the best
	possible resolution in velocity space. The size of the resulting
	nonlinear system of equations is immense, but using a few iterations
	with a gradient descent algorithm is adequate to obtain a reasonable
	solution. This theory may also be applied to other large, sparse
	linear operators. The stochastic inverse of the slant-stack operator
	(a particular form of the Radon transform), can be developed in a
	parallel manner, and will yield an accurate slant-stack inverse pair.
	{\copyright}1985 Society of Exploration Geophysicists},
  bdsk-url-1 = {http://dx.doi.org/10.1190/1.1441893},
  date-added = {2008-05-06 19:06:15 -0700},
  date-modified = {2008-08-14 15:20:19 -0700},
  doi = {10.1190/1.1441893},
  issue = {12},
  keywords = {Radon transform},
  publisher = {SEG}
}

@ARTICLE{trad03lvo,
  author = {D. Trad and T. J. Ulrych and M. D. Sacchi},
  title = {Latest views of the sparse {R}adon transform},
  journal = {Geophysics},
  year = {2003},
  volume = {68},
  pages = {386-399},
  number = {1},
  abstract = {The Radon transform (RT) suffers from the typical problems of loss
	of resolution and aliasing that arise as a consequence of incomplete
	information, including limited aperture and discretization. Sparseness
	in the Radon domain is a valid and useful criterion for supplying
	this missing information, equivalent somehow to assuming smooth amplitude
	variation in the transition between known and unknown (missing) data.
	Applying this constraint while honoring the data can become a serious
	challenge for routine seismic processing because of the very limited
	processing time available, in general, per common midpoint. To develop
	methods that are robust, easy to use and flexible to adapt to different
	problems we have to pay attention to a variety of algorithms, operator
	design, and estimation of the hyperparameters that are responsible
	for the regularization of the solution.In this paper, we discuss
	fast implementations for several varieties of RT in the time and
	frequency domains. An iterative conjugate gradient algorithm with
	fast Fourier transform multiplication is used in all cases. To preserve
	the important property of iterative subspace methods of regularizing
	the solution by the number of iterations, the model weights are incorporated
	into the operators. This turns out to be of particular importance,
	and it can be understood in terms of the singular vectors of the
	weighted transform. The iterative algorithm is stopped according
	to a general cross validation criterion for subspaces. We apply this
	idea to several known implementations and compare results in order
	to better understand differences between, and merits of, these algorithms.
	{\copyright}2003 Society of Exploration Geophysicists},
  bdsk-url-1 = {http://link.aip.org/link/?GPY/68/386/1},
  bdsk-url-2 = {http://dx.doi.org/10.1190/1.1543224},
  date-added = {2008-05-07 19:03:39 -0700},
  date-modified = {2008-08-14 15:20:56 -0700},
  doi = {10.1190/1.1543224},
  issue = {1},
  keywords = {Radon transform},
  pdf = {http://link.aip.org/link/?GPY/68/386/1},
  publisher = {SEG}
}

@ARTICLE{verschuur97eom,
  author = {D. J. Verschuur and A. J. Berkhout},
  title = {Estimation of multiple scattering by iterative inversion, Part {II}:
	Practical aspects and examples},
  journal = {Geophysics},
  year = {1997},
  volume = {62},
  pages = {1596-1611},
  number = {5},
  abstract = {A surface-related multiple-elimination method can be formulated as
	an iterative procedure: the output of one iteration step is used
	as input for the next iteration step (part I of this paper). In this
	paper (part II) it is shown that the procedure can be made very efficient
	if a good initial estimate of the multiple-free data set can be provided
	in the first iteration, and in many situations, the Radon-based multiple-elimination
	method may provide such an estimate. It is also shown that for each
	iteration, the inverse source wavelet can be accurately estimated
	by a linear (least-squares) inversion process. Optionally, source
	and detector variations and directivity effects can be included,
	although the examples are given without these options. The iterative
	multiple elimination process, together with the source wavelet estimation,
	are illustrated with numerical experiments as well as with field
	data examples. The results show that the surface-related multiple-elimination
	process is very effective in time gates where the moveout properties
	of primaries and multiples are very similar (generally deep data),
	as well as for situations with a complex multiple-generating system.
	{\copyright}1997 Society of Exploration Geophysicists},
  bdsk-url-1 = {http://link.aip.org/link/?GPY/62/1596/1},
  bdsk-url-2 = {http://dx.doi.org/10.1190/1.1444262},
  date-added = {2008-05-07 18:40:45 -0700},
  date-modified = {2008-08-14 15:21:18 -0700},
  doi = {10.1190/1.1444262},
  issue = {5},
  keywords = {SRME},
  pdf = {http://link.aip.org/link/?GPY/62/1596/1},
  publisher = {SEG}
}

@ARTICLE{xu05aft,
  author = {S. Xu and Y. Zhang and D. Pham and G. Lambar\'{e}},
  title = {Antileakage {F}ourier transform for seismic data regularization},
  journal = {Geophysics},
  year = {2005},
  volume = {70},
  pages = {V87-V95},
  number = {4},
  abstract = {Seismic data regularization, which spatially transforms irregularly
	sampled acquired data to regularly sampled data, is a long-standing
	problem in seismic data processing. Data regularization can be implemented
	using Fourier theory by using a method that estimates the spatial
	frequency content on an irregularly sampled grid. The data can then
	be reconstructed on any desired grid. Difficulties arise from the
	nonorthogonality of the global Fourier basis functions on an irregular
	grid, which results in the problem of "spectral leakage": energy
	from one Fourier coefficient leaks onto others. We investigate the
	nonorthogonality of the Fourier basis on an irregularly sampled grid
	and propose a technique called "antileakage Fourier transform" to
	overcome the spectral leakage. In the antileakage Fourier transform,
	we first solve for the most energetic Fourier coefficient, assuming
	that it causes the most severe leakage. To attenuate all aliases
	and the leakage of this component onto other Fourier coefficients,
	the data component corresponding to this most energetic Fourier coefficient
	is subtracted from the original input on the irregular grid. We then
	use this new input to solve for the next Fourier coefficient, repeating
	the procedure until all Fourier coefficients are estimated. This
	procedure is equivalent to "reorthogonalizing" the global Fourier
	basis on an irregularly sampled grid. We demonstrate the robustness
	and effectiveness of this technique with successful applications
	to both synthetic and real data examples. {\copyright}2005 Society
	of Exploration Geophysicists},
  bdsk-url-1 = {http://link.aip.org/link/?GPY/70/V87/1},
  bdsk-url-2 = {http://dx.doi.org/10.1190/1.1993713},
  date-added = {2008-05-09 17:43:47 -0700},
  date-modified = {2008-08-14 15:21:45 -0700},
  doi = {10.1190/1.1993713},
  issue = {4},
  keywords = {Fourier transform, reconstruction},
  pdf = {http://link.aip.org/link/?GPY/70/V87/1},
  publisher = {SEG}
}

@ARTICLE{ying053dd,
  author = {L. Ying and L. Demanet and E. J. Cand\`es},
  title = {{3-D} discrete curvelet transform},
  journal = {Proceedings SPIE wavelets XI, San Diego},
  year = {2005},
  volume = {5914},
  pages = {344-354},
  month = {January},
  abstract = {In this paper, we present the first 3D discrete curvelet transform.
	This transform is an extension to the 2D transform described in Candes
	et al..1 The resulting curvelet frame preserves the important properties,
	such as parabolic scaling, tightness and sparse representation for
	singularities of codimension one. We describe three different implementations:
	in-core, out-of-core and MPI-based parallel implementations. Numerical
	results verify the desired properties of the 3D curvelets and demonstrate
	the efficiency of our implementations. },
  bdsk-url-1 = {http://dx.doi.org/10.1117/12.616205},
  date-added = {2008-05-07 14:14:59 -0700},
  date-modified = {2008-08-14 15:21:59 -0700},
  doi = {10.1117/12.616205},
  keywords = {curvelet transform}
}

@PHDTHESIS{zwartjes05phd,
  author = {P. M. Zwartjes},
  title = {Fourier reconstruction with sparse inversion},
  school = {Delft University of Technology},
  year = {2005},
  address = {Delft, The Netherlands},
  month = {December},
  date-added = {2008-05-06 18:58:35 -0700},
  date-modified = {2008-05-09 14:44:04 -0700},
  keywords = {Fourier transform, reconstruction},
  rating = {0},
  read = {Yes}
}

