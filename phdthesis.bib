% This file was created with JabRef 2.9.
% Encoding: ISO8859_1

%-----2017-----%

@PHDTHESIS{oghenekohwo2017THetl,
  author = {Felix Oghenekohwo},
  title = {Economic time-lapse seismic acquisition and imaging---{Reaping} the benefits of randomized sampling with distributed compressive sensing},
  school = {The University of British Columbia},
  year = {2017},
  month = {08},
  address = {Vancouver},
  abstract = {This thesis presents a novel viewpoint on the implicit
                  opportunities randomized surveys bring to time-lapse
                  seismic - which is a proven surveillance tool for
                  hydrocarbon reservoir monitoring. Time-lapse (4D)
                  seismic combines acquisition and processing of at
                  least two seismic datasets (or vintages) in order to
                  extract information related to changes in a
                  reservoir within a specified time interval. The
                  current paradigm places stringent requirements on
                  replicating the 4D surveys, which is an expensive
                  task often requiring uneconomical dense sampling of
                  seismic wavefields. To mitigate the challenges of
                  dense sampling, several advances in seismic
                  acquisition have been made in recent years including
                  the use of multiple sources firing at near
                  simultaneous random times, and the adaptation of
                  Compressive Sensing (CS) principles to design
                  practical acquisition engines that improve sampling
                  efficiency for seismic data acquisition. However,
                  little is known regarding the implications of these
                  developments for time-lapse studies. By conducting
                  multiple experiments modelling surveys adhering to
                  the principles of CS for 4D seismic, I propose a
                  model that demonstrates the feasibility of
                  randomized acquisitions for time-lapse seismic. The
                  proposed joint recovery model (JRM), which derives
                  from distributed CS, exploits the common information
                  in time-lapse data during recovery of dense
                  wavefields from measured subsampled data, providing
                  highly repeatable and high-fidelity vintages. I show
                  that we obtain better vintages when randomized
                  surveys are not replicated, in contrast to standard
                  practice, paving the way for an opportunity to relax
                  the rigorous requirement to replicate surveys
                  precisely. We assert that the vintages obtained
                  using our proposed model are of sufficient quality
                  to serve as inputs to processes that extract
                  time-lapse attributes from which subsurface changes
                  are deduced. Additionally, I show that recovery with
                  the JRM is robust with respect to errors due to
                  differences between actual and recorded postplot
                  information. Finally, I present an opportunity to
                  adapt our model to problems related to time-lapse
                  seismic imaging where the main finding is that we
                  can better delineate time-lapse changes by adapting
                  the joint recovery model to wave-equation based
                  inversion methods.},
  keywords = {PhD, time lapse, acquisition, joint recovery, thesis, compressive sensing, distributed compressive sensing},
  note = {(PhD)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Thesis/2017/oghenekohwo2017THetl/oghenekohwo2017THetl.pdf},
  presentation = {https://www.slim.eos.ubc.ca/Publications/Public/Thesis/2017/oghenekohwo2017THetl/oghenekohwo2017THetl_pres.pdf}
}


%-----2015-----%

@PHDTHESIS{lin2015THpes,
  author = {Tim T.Y. Lin},
  title = {Primary estimation with sparsity-promoting bi-convex optimization},
  school = {The University of British Columbia},
  year = {2015},
  month = {10},
  address = {Vancouver},
  abstract = {This thesis establishes a novel inversion methodology
                  for the surface-related primaries from a given
                  recorded seismic wavefield, called the Robust
                  Estimation of Primaries by Sparse Inversion (Robust
                  EPSI, or REPSI). Surface-related multiples are a
                  major source of coherent noise in seismic data, and
                  inferring fine geological structures from
                  active-source seismic recordings typically first
                  necessitates its removal or mitigation. For this
                  task, current practice calls for data-driven
                  approaches which produce only approximate multiple
                  models that must be non-linearly subtracted from the
                  data, often distorting weak primary events in the
                  process. A recently proposed method called
                  Estimation of Primaries by Sparse Inversion (EPSI)
                  avoids this adaptive subtraction by directly
                  inverting for a discrete representation of the
                  underlying multiple-free subsurface impulse response
                  as a set of band-limited spikes. However, in its
                  original form, the EPSI algorithm exhibits a few
                  notable shortcomings that impede adoption. Although
                  it was shown that the correct impulse response can
                  be obtained through a sparsest solution criteria,
                  the current EPSI algorithm is not designed to take
                  advantage of this finding, but instead approximates
                  a sparse solution in an ad-hoc manner that requires
                  practitioners to decide on a multitude of inversion
                  parameters. The Robust EPSI method introduced in
                  this thesis reformulates the original EPSI problem
                  as a formal bi-convex optimization problem that
                  makes obtaining the sparsest solution an explicit
                  goal, while also reliably admit satisfactory
                  solutions using contemporary self-tuning gradient
                  methods commonly seen in large-scale machine
                  learning communities. I show that the Robust EPSI
                  algorithm is able to operate successfully on a
                  variety of datasets with minimal user input, while
                  also producing a more accurate model of the
                  subsurface impulse response when compared to the
                  original algorithm. Furthermore, this thesis makes
                  several contributions that improves the capability
                  and practicality of EPSI: a novel scattering-based
                  multiple prediction model that allows Robust EPSI to
                  deal with wider near-offset receiver gaps than
                  previously demonstrated for EPSI, as well as a
                  multigrid-inspired continuation strategy that
                  significantly reduces the computation time needed to
                  solve EPSI-type problems. These additions are
                  enabled by and built upon the formalism of the
                  Robust EPSI as developed in this thesis.},
  keywords = {PhD, inversion, EPSI, biconvex, multiples, sparsity, optimization},
  note = {(PhD)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Thesis/2015/lin2015THpes/lin2015THpes.pdf},
  presentation = {https://www.slim.eos.ubc.ca/Publications/Public/Thesis/2015/lin2015THpes/lin2015THpes_pres.pdf}
}


@PHDTHESIS{tu2015THfis,
  author = {Ning Tu},
  title = {Fast imaging with surface-related multiples},
  school = {The University of British Columbia},
  year = {2015},
  month = {08},
  address = {Vancouver},
  abstract = {Surface-related multiples, which are waves that bounce
                  more than once between the water surface and the
                  subsurface reflectors, constitute a significant part
                  of the data acquired in marine seismic surveys. If
                  left untreated, they can lead to misplaced phantom
                  reflectors in the image, and result in erroneous
                  interpretations of the subsurface structure. As a
                  result, these multiples are removed before the
                  imaging procedure in conventional seismic data
                  processing. However, because they interact more with
                  the subsurface medium, they may carry extra
                  information that is not present in the primaries.
                  Therefore instead of removing these multiples, a
                  more desirable alternative is to make active use of
                  them. We derive from the well-established
                  "Surface-Related Multiple Elimination" relation, and
                  arrive at a linearized expression of the
                  wave-equation based modelling that incorporates the
                  surface- related multiples.  We then present a
                  computationally efficient approach to iteratively
                  invert this expression to obtain an image of the
                  subsurface from data that contain multiples. We
                  achieve the computational efficiency inside each
                  iteration by (i) using the wave-equation solver to
                  implicitly carry out the expensive multiple
                  prediction; and (ii) reducing the number of
                  wave-equation solves during data simulation by
                  subsampling the monochromatic source experiments. We
                  show that, compared with directly applying the
                  cross-correlation/deconvolutional imaging
                  conditions, the presented approach can suppress the
                  coherent imaging artifacts from multiples more
                  effectively. We also show that, by curvelet-domain
                  sparsity promoting and occasionally drawing new data
                  samples during the inversion, the proposed inversion
                  method gains improved robustness to velocity errors
                  in the background model, as well as modelling errors
                  incurred during linearization of the
                  wave-equation. To combine the information encoded in
                  both the primaries and the multiples, we then
                  propose a highly accurate source estimation method
                  to jointly invert the total upgoing wavefield. We
                  show with field data examples that we can reap
                  benefits from both the relative noise-free primaries
                  and the extra illumination coverage of the
                  multiples. We also demonstrate that the inclusion of
                  multiples help mitigate the amplitude ambiguity
                  during source estimation. We conclude the thesis
                  with an outlook for future research directions, as
                  well as potential extensions of the proposed work.},
  keywords = {inversion, seismic imaging, multiples, least-squares},
  note = {(PhD)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Thesis/2015/tu2015THfis/tu2015THfis.pdf},
  presentation = {https://www.slim.eos.ubc.ca/Publications/Public/Thesis/2015/tu2015THfis/tu2015THfis_pres.pdf}
}


@PHDTHESIS{li2015THsps,
  author = {Xiang Li},
  title = {Sparsity promoting seismic imaging and full-waveform inversion},
  school = {The University of British Columbia},
  year = {2015},
  month = {07},
  address = {Vancouver},
  abstract = {This thesis will address the large computational costs
                  of solving least-squares migration and full-waveform
                  inversion problems. Least-squares seismic imaging
                  and full-waveform inversion are seismic inversion
                  techniques that require iterative minimizations of
                  large least-squares misfit functions. Each iteration
                  requires an evaluation of the Jacobian operator and
                  its adjoint, both of which require two wave-equation
                  solves for all sources, creating prohibitive
                  computational costs. In order to reduce costs, we
                  utilize randomized dimensionality reduction
                  techniques, reducing the number of sources used
                  during inversion. The randomized dimensionality
                  reduction techniques create subsampling related
                  artifacts, which we mitigate by using
                  curvelet-domain sparsity-promoting inversion
                  techniques. Our method conducts least-squares
                  imaging at the approximate cost of one reverse-time
                  migration with all sources, and computes the
                  Gauss-Newton full-waveform inversion update at
                  roughly the cost of one gradient update with all
                  sources. Finally, during our research of the
                  full-waveform inversion problem, we discovered that
                  we can utilize our method as an alternative approach
                  to add sparse constraints on the entire velocity
                  model by imposing sparsity constraints on each model
                  update separately, rather than regularizing the
                  total velocity model as typically practiced. We also
                  observed this alternative approach yields a faster
                  decay of the residual and model error as a function
                  of iterations. We provided empirical arguments why
                  and when imposing sparsity on the updates can lead
                  to improved full-waveform inversion results.},
  keywords = {full-waveform inversion, Gauss-Newton method, sparsity promoting, least-squares imaging, seismic imaging},
  note = {(PhD)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Thesis/2015/li2015THsps/li2015THsps.pdf},
  presentation = {https://www.slim.eos.ubc.ca/Publications/Public/Thesis/2015/li2015THsps/li2015THsps_pres.pdf}
}


%-----2010-----%

@PHDTHESIS{moghaddam10phd,
  author = {Peyman P. Moghaddam},
  title = {Curvelet-based migration amplitude recovery},
  school = {The University of British Columbia},
  year = {2010},
  month = {05},
  address = {Vancouver},
  abstract = {Migration can accurately locate reflectors in the earth
                  but in most cases fails to correctly resolve their
                  amplitude. This might lead to mis-interpretation of
                  the nature of reflector. In this thesis, I
                  introduced a method to accurately recover the
                  amplitude of the seismic reflector. This method
                  relies on a new transform-based recovery that
                  exploits the expression of seismic images by the
                  recently developed curvelet transform. The elements
                  of this transform, called curvelets, are
                  multi-dimensional, multi-scale, and
                  multi-directional. They also remain approximately
                  invariant under the imaging operator. I exploit
                  these properties of the curvelets to introduce a
                  method called Curvelet Match Filtering (CMF) for
                  recovering the seismic amplitude in presence of
                  noise in both migrated image and data. I detail the
                  method and illustrate its performance on synthetic
                  dataset. I also extend CMF formulation to other
                  geophysical applications and present results on
                  multiple removal. In addition of that, I investigate
                  preconditioning of the migration which results to
                  rapid convergence rate of the iterative method using
                  migration.},
  note = {(PhD)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Thesis/2010/moghaddam10phd.pdf}
}


%-----2008-----%

@PHDTHESIS{hennenfent08phd,
  author = {Gilles Hennenfent},
  title = {Sampling and reconstruction of seismic wavefields in the curvelet domain},
  school = {The University of British Columbia},
  year = {2008},
  month = {05},
  address = {Vancouver},
  abstract = {Wavefield reconstruction is a crucial step in the
                  seismic processing flow. For instance, unsuccessful
                  interpolation leads to erroneous multiple
                  predictions that adversely affect the performance of
                  multiple elimination, and to imaging artifacts. We
                  present a new non-parametric transform-based
                  reconstruction method that exploits the compression
                  of seismic data by the recently developed curvelet
                  transform. The elements of this transform, called
                  curvelets, are multi-dimensional, multi-scale, and
                  multi-directional. They locally resemble wavefronts
                  present in the data, which leads to a compressible
                  representation for seismic data. This compression
                  enables us to formulate a new curvelet-based seismic
                  data recovery algorithm through sparsity-promoting
                  inversion (CRSI). The concept of sparsity-promoting
                  inversion is in itself not new to
                  geophysics. However, the recent insights from the
                  field of {\textquoteleft}{\textquoteleft}compressed
                  sensing{\textquoteright}{\textquoteright} are new
                  since they clearly identify the three main
                  ingredients that go into a successful formulation of
                  a reconstruction problem, namely a sparsifying
                  transform, a sub-Nyquist sampling strategy that
                  subdues coherent aliases in the sparsifying domain,
                  and a data-consistent sparsity-promoting
                  program. After a brief overview of the curvelet
                  transform and our seismic-oriented extension to the
                  fast discrete curvelet transform, we detail the CRSI
                  formulation and illustrate its performance on
                  synthetic and real datasets. Then, we introduce a
                  sub-Nyquist sampling scheme, termed jittered
                  undersampling, and show that, for the same amount of
                  data acquired, jittered data are best interpolated
                  using CRSI compared to regular or random
                  undersampled data. We also discuss the large-scale
                  one-norm solver involved in CRSI. Finally, we extend
                  CRSI formulation to other geophysical applications
                  and present results on multiple removal and
                  migration-amplitude recovery.},
  keywords = {curvelet transform, reconstruction, SLIM},
  note = {(PhD)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Thesis/2008/hennenfent08phd.pdf}
}

