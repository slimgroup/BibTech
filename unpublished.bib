% This file was created with JabRef 2.9.
% Encoding: MacRoman

%-----2019-----%

@UNPUBLISHED{herrmann2019NIPSliwcuc,
  author = {Felix J. Herrmann and Ali Siahkoohi and Gabrio Rizzuti},
  title = {Learned imaging with constraints and uncertainty quantification},
  year = {2019},
  abstract = {We outline new approaches to incorporate ideas from convolutional
networks into wave-based least-squares imaging. The aim is to combine
hand-crafted constraints with deep convolutional networks allowing us to
directly train a network capable of generating samples from the posterior. The main contributions include combination of weak deep priors with hard handcrafted constraints and a possible new way to sample the posterior.},
  keywords = {imaging, deep learning, uncertainty quantification, constraint, private},
  note = {Submitted to NIPS on September 9, 2019},
  url = {https://arxiv.org/pdf/1909.06473.pdf}
}

@UNPUBLISHED{witte2019TPDedas,
  author = {Philipp A. Witte and Mathias Louboutin and Henryk Modzelewski and Charles Jones and James Selvage and Felix J. Herrmann},
  title = {An Event-Driven Approach to Serverless Seismic Imaging in the Cloud},
  year = {2019},
  abstract = {Adapting the cloud for high-performance computing (HPC) is a
challenging task, as software for HPC applications hinges on fast network
connections and is sensitive to hardware failures. Using cloud infrastructure
to recreate conventional HPC clusters is therefore in many cases an
infeasible solution for migrating HPC applications to the cloud. As an
alternative to the generic lift and shift approach, we consider the specific
application of seismic imaging and demonstrate a serverless and event-driven
pproach for running large-scale instances of this problem in the cloud.
Instead of permanently running compute instances, our workflow is based on a
serverless architecture with high throughput batch computing and event-driven
computations, in which computational resources are only running as long as
they are utilized. We demonstrate that this approach is very flexible and
allows for resilient and nested levels of parallelization, including domain
decomposition for solving the underlying partial differential equations.
While the event-driven approach introduces some overhead as computational
resources are repeatedly restarted, it inherently provides resilience to
instance shut-downs and allows a significant reduction of cost by avoiding
idle instances, thus making the cloud a viable alternative to on-premise
clusters for large-scale seismic imaging.},
  keywords = {cloud, imaging, serverless, event-driven, lsrtm, private},
  note = {Submitted to IEEE Transactions on Parallel and Distributed Systems on August 20, 2019},
  url = {https://slim.gatech.edu/Publications/Private/Submitted/2019/witte2019TPDedas/witte2019TPDedas.html}
}

@UNPUBLISHED{kukreja2019PASCccd,
  author = {Navjot Kukreja and Jan Huckelheim and Mathias Louboutin and Kaiyuan Hou and Paul Hovland and Gerard Gorman},
  title = {Combining checkpointing and data compression to accelerate adjoint-based optimization problems},
  year = {2019},
  abstract = {Seismic inversion and imaging are adjoint-based optimization problems that processes up to terabytes of data, regularly exceeding the memory capacity of available computers. Data compression is an effective strategy to reduce this memory requirement by a certain factor, particularly if some loss in accuracy is acceptable. A popular alternative is checkpointing, where data is stored at selected points in time, and values at other times are recomputed as needed from the last stored state. This allows arbitrarily large adjoint computations with limited memory, at the cost of additional recomputations. In this paper we combine compression and checkpointing for the first time to compute a realistic seismic inversion. The combination of checkpointing and compression allows larger adjoint computations compared to using only compression, and reduces the recomputation overhead significantly compared to using only checkpointing.},
  keywords = {Adjoint-state, FD, checkpointing, compression, HPC, inverse problems, private},
  note = {Submitted to PASC19 on January 16, 2019},
  url = {https://slim.gatech.edu/Publications/Private/Submitted/2019/kukreja2019PASCccd/kukreja2019PASCccd.pdf}
}



%-----2018-----%

@UNPUBLISHED{luporini2018aap,
  author = {FABIO LUPORINI and MICHAEL LANGE and MATHIAS LOUBOUTIN and NAVJOT KUKREJA and JAN HUCKELHEIM and CHARLES YOUNT and PHILIPP A. WITTE and PAUL H. J. KELLY and GERARD J. GORMAN and FELIX J. HERRMANN},
  title = {Architecture and performance of Devito, a system for automated stencil computation},
  year = {2018},
  abstract = {Stencil computations are a key part of many high-performance computing applications, such as image processing, convolutional neural networks, and finite-difference solvers for partial differential equations. Devito is a framework capable of generating highly-optimized code given symbolic equations expressed in Python, specialized in, but not limited to, affine (stencil) codes. The lowering process – from mathematical equations down to C++ code – is
performed by the Devito compiler through a series of intermediate representations. Several performance optimizations are introduced, including advanced common sub-expressions elimination, tiling and parallelization. Some of these are obtained through well-established stencil optimizers, integrated in the back-end of the Devito compiler. The architecture of the Devito compiler, as well as the performance optimizations that are applied when generating code, are presented. The effectiveness of such performance optimizations is demonstrated using operators drawn from seismic imaging applications.},
  keywords = {Stencil, finite difference method, symbolic processing, structured grid, compiler, performance optimization, private},
  note = {Submitted to SIAM Journal on Scientific Computing on July 9, 2018.},
  url = {https://slim.gatech.edu/Publications/Private/Submitted/2018/luporini2018aap/luporini2018aap.pdf}
}