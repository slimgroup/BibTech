% This file was created with JabRef 2.6.
% Encoding: MacRoman

@unpublished{vanleeuwen2012smii,
author = {Tristan {van Leeuwen}},
year = {2012},
optmonth = {07/2012},
title = {A parallel matrix-free framework for frequency-domain seismic modelling, imaging and inversion in Matlab},
abstract = {I present a parallel matrix-free framework for
                  frequency-domain seismic modeling, imaging and
                  inversion. The framework provides basic building
                  blocks for designing and testing optimization-based
                  formulations of both linear and non-linear seismic
                  in- verse problems. By overloading standard
                  linear-algebra operations, such as matrix- vector
                  multiplications, standard optimization packages can
                  be used to work with the code without any
                  modification. This leads to a scalable testbed on
                  which new methods can be rapidly prototyped and
                  tested on medium-sized 2D problems. I present some
                  numerical examples on both linear and non-linear
                  seismic inverse problems.},
keywords = {Seismic imaging,optimization,Matlab,object-oriented programming},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/Journal/vanleeuwen2012smii/vanleeuwen2012smii.pdf}
}


@unpublished{aravkin2012IPNuisance,
author = {Aleksandr Y. Aravkin and Tristan {van Leeuwen}},
year = {2012},
optmonth = {06/2012},
title = {Estimating Nuisance Parameters in Inverse Problems},
abstract = {Many inverse problems include nuisance parameters which,
                  while not of direct interest, are required to
                  recover primary parameters. Structure present in
                  these problems allows efficient optimization
                  strategies - a well known example is variable
                  projection, where nonlinear least squares problems
                  which are linear in some parameters can be very
                  efficiently optimized. In this paper, we extend the
                  idea of projecting out a subset over the variables
                  to a broad class of maximum likelihood (ML) and
                  maximum a posteriori likelihood (MAP) problems with
                  nuisance parameters, such as variance or degrees of
                  freedom. As a result, we are able to incorporate
                  nuisance parameter estimation into large-scale
                  constrained and unconstrained inverse problem
                  formulations. We apply the approach to a variety of
                  problems, including estimation of unknown variance
                  parameters in the Gaussian model, degree of freedom
                  (d.o.f.) parameter estimation in the context of
                  robust inverse problems, automatic calibration, and
                  optimal experimental design. Using numerical
                  examples, we demonstrate improvement in recovery of
                  primary parameters for several large- scale inverse
                  problems. The proposed approach is compatible with a
                  wide variety of algorithms and formulations, and its
                  implementation requires only minor modifications to
                  existing algorithms.},
keywords = {full waveform inversion, students t, variance},
url = {http://arxiv.org/abs/1206.6532}
}

@unpublished{lin2012robustepsi,
author = {Tim T.Y. Lin and Felix J. Herrmann},
year = {2012},
optmonth = {03/2012},
title = {Robust estimation of primaries by sparse inversion via one-norm minimization},
abstract = {Even though contemporary methods for the removal of multiple 
events in seismic data due to a free-surface are built upon reciprocity 
relationships between wavefields, they are often still implemented as 
prediction-subtraction processes. The subtraction process does not always 
compensate for imperfect prediction of multiple events, and itself often 
leads to distortion of primary events. A recently proposed method called 
Estimation of Primaries by Sparse Inversion avoids the subtraction process 
altogether by directly prediction the primary impulse response as a collection 
of band-limited spikes under sparsity-regulated wavefield inversion approach. 
Although it can be shown that the correct primary impulse response is 
obtained through the sparsest possible solution, the Estimation of Primaries 
by Sparse Inversion algorithm was not designed to seek such a solution, instead 
depending on a predetermined degree of sparsity as an inversion parameter. 
This leads to imperfect multiple rejection when the sparsity is overestimated, 
and problems with recovering late primary events when it is underestimated. 
In this paper, we propose a new algorithm where we make obtaining the 
sparsest solution our explicit goal. Our approach remains a gradient-based 
approach like the original algorithm, but is in turn derived from a new 
optimization framework based on an extended basis pursuit denoising formulation. 
We show that the sparsity-minimizing objective of our formulation enables it 
to operate successfully on a wide variety of synthetic and field marine dataset 
without excessive tweaking of inversion parameters. We also demonstrate that 
Robust EPSI produces a more artifact-free impulse response compared to the 
original algorithm, which has interesting implications for broadband seismic 
applications. Finally we demonstrate through field data that recovering the 
primary impulse response under transform domains can significantly improve 
the recovery of weak primary late arrivals, without appreciable change to the 
underlying algorithm.},
keywords = {multiples, optimization, sparsity, waveform inversion, pareto, biconvex, algorithm, EPSI},
notes = {submitted to Geophysics, March 12, 2012},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/Journal/lin2012robustepsi/lin2012robustepsi.pdf}
}

@unpublished{bander2012dre,
author = {Bander Jumah and Felix J. Herrmann},
year = {2012},
optmonth = {02/2012},
title = {Dimensionality-reduced estimation of primaries by sparse inversion},
abstract = {Data-driven methods---such as the estimation of primaries by sparse 
inversion---suffer from the 'curse of dimensionality' that leads to 
disproportional growth in computational and storage demands when 
moving to realistic 3D field data. To remove this fundamental 
impediment, we propose a dimensionality-reduction technique where 
the 'data matrix' is approximated adaptively by a randomized 
low-rank factorization. Compared to conventional methods, which need 
for each iteration passage through all data possibly requiring 
on-the-fly interpolation, our randomized approach has the advantage 
that the total number of passes is reduced to only one to three. In 
addition, the low-rank matrix factorization leads to considerable 
reductions in storage and computational costs of the matrix 
multiplies required by the sparse inversion. Application of the 
proposed method to synthetic and real data shows that significant 
performance improvements in speed and memory use are achievable at a 
low computational up-front cost required by the low-rank 
factorization.},
keywords = {multiples,Processing,Optimization},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/Journal/bander2012dre/bander2012dre.pdf}
}

@unpublished{Friedlander11TRhdm,
  author = {Michael P. Friedlander and Mark Schmidt},
  title = {Hybrid deterministic-stochastic methods for data fitting},
  institution = {Department of Computer Science},
  year = {2011},
  address = {University of British Columbia, Vancouver},
  optmonth = {04/2011},
  abstract = {Many structured data-fitting applications require the
                  solution of an optimization problem involving a sum
                  over a potentially large number of
                  measurements. Incremental gradient algorithms (both
                  deterministic and randomized) offer inexpensive
                  iterations by sampling only subsets of the terms in
                  the sum. These methods can make great progress
                  initially, but often slow as they approach a
                  solution. In contrast, full gradient methods achieve
                  steady convergence at the expense of evaluating the
                  full objective and gradient on each iteration. We
                  explore hybrid methods that exhibit the benefits of
                  both approaches. Rate of convergence analysis and
                  numerical experiments illustrate the potential for
                  the approach.},
  publisher = {Department of Computer Science},
  keywords ={Optimization},
  url = {http://www.cs.ubc.ca/~mpf/papers/FriedlanderSchmidt2011.pdf}
}

@unpublished{Mansour11TRwmmw,
  author = {Hassan Mansour and Ozgur Yilmaz.},
  title = {Weighted -$\ell_1$ minimization with multiple weighting sets},
  year = {2011},
  type = {Tech. Rep.},
  address = {University of British Columbia, Vancouver},
  optmonth = {09/2011},
notes= {TR-2011-07 },
  abstract = {In this paper, we study the support In this paper, we
                  study the support recovery conditions of weighted
                  -$\ell_1$ minimization for signal reconstruction
                  from compressed sensing measurements when multiple
                  support estimate sets with different accuracy are
                  available. We identify a class of signals for which
                  the recovered vector from -$\ell_1$ minimization
                  provides an accurate support estimate. We then
                  derive stability and robustness guarantees for the
                  weighted -$\ell_1$ minimization problem with more
                  than one support estimate. We show that applying a
                  smaller weight to support estimate that enjoy higher
                  accuracy improves the recovery conditions compared
                  with the case of a single support estimate and the
                  case with standard, i.e., non-weighted,-$\ell_1$
                  minimization. Our theoretical results are supported
                  by numerical simulations on synthetic signals and
                  real audio signals.},
keywords={Compressive Sensing,Optimization},
  url = {http://slim.eos.ubc.ca/Publications/private/Journals/MansourYilmaz2011.pdf }
}

% Check with Michael whether this will be publsihed or stays as an technical report
@unpublished{vandenberg08gsv,
  author = {Ewout {van den Berg} and Mark Schmidt and Michael P. Friedlander and K.
	Murphy},
  title = {Group sparsity via linear-time projection},
institution = {UBC-Computer Science Department},
  year = {2008},
    number = {TR-2008-1},
  abstract = {We present an efficient spectral projected-gradient algorithm for
	optimization subject to a group one-norm constraint. Our approach
	is based on a novel linear-time algorithm for Euclidean projection
	onto the one- and group one-norm constraints. Numerical experiments
	on large data sets suggest that the proposed method is substantially
	more efficient and scalable than existing methods.},
  keywords = {SLIM,Optimization},
  url = {http://www.optimization-online.org/DB_FILE/2008/07/2056.pdf}
}

