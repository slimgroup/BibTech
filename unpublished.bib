% This file was created with JabRef 2.9.
% Encoding: MacRoman

%-----2014-----%

@UNPUBLISHED{oghenekohwo2014GEOPfrt,
  author = {Felix Oghenekohwo and Haneet Wason and Ernie Esser and Felix J. Herrmann},
  title = {Foregoing repetition in time-lapse seismic --- reaping benefits of randomized sampling and joint recovery},
  year = {2014},
  month = {06},
  institution = {UBC},
  abstract = {In the current paradigm of time-lapse seismic,
                  guaranteeing repeatability in acquisition and
                  processing of the baseline and monitor surveys ranks
                  amongst the highest technical challenges we are
                  faced with when recovering useful 4-D
                  information. By using recent insights from the field
                  of distributed compressive sensing, we show that
                  under certain conditions, the constraint of survey
                  repeatability can be relaxed as long as we jointly
                  invert the different surveys from randomized
                  samplings via a sparsity-promoting program that
                  exploits shared information amongst the baseline and
                  monitor surveys. Motivated by a series of stylized
                  examples, which demonstrate the benefits of
                  exploiting correlations between the vintages through
                  joint recovery, we are able to compute high-fidelity
                  time-lapse vintages and differences from randomly
                  jittered simultaneous-source marine
                  acquisitions. Results from both the stylized
                  examples and realistic marine synthetics show that
                  the recovery of the vintages and time-lapse signal
                  improve when we bestow a certain degree of
                  independence on the randomized acquisitions of the
                  different surveys. This suggests that by foregoing
                  our insistence on strict repetition in time-lapse
                  seismic, we will be opening fundamentally new
                  opportunities to improve the quality and
                  cost-effectiveness of time-lapse seismic
                  acquisition. Our numerical experiments on a
                  realistic synthetic confirms this enticing premise.},
  keywords = {acquistion, time-lapse, marine, sampling, random, joint recovery method, private},
  note = {Submitted to Geophysics on June 9, 2014.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2014/oghenekohwo2014GEOPfrt/oghenekohwo2014GEOPfrt.html}
}


@UNPUBLISHED{vanLeeuwen2014pmpde,
  author = {Tristan van Leeuwen and Felix J. Herrmann},
  title = {A penalty method for {PDE}-constrained optimization ({CONFIDENTIAL})},
  year = {2014},
  month = {04},
  institution = {UBC},
  abstract = {The invention relates to a partial-differential-equation
                  (PDE) constrained optimization method and especially
                  to a partial-differential-equation (PDE) constrained
                  optimization method for geophysical prospecting.},
  keywords = {FWI, optimization, patent, private},
  note = {Patent filed on April 22, 2014. PCT International Application.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2014/vanLeeuwen2014pmpde/vanLeeuwen2014pmpde.pdf}
}


@UNPUBLISHED{lin2014SEGmdg,
  author = {Tim T.Y. Lin and Felix J. Herrmann},
  title = {Mitigating data gaps in the estimation of primaries by sparse inversion without data reconstruction},
  year = {2014},
  month = {04},
  institution = {UBC},
  abstract = {We propose to solve the Estimation of Primaries by
                  Sparse Inversion problem from a sesimic record with
                  missing near-offsets and large holes without any
                  explicit data reconstruction, by instead simulating
                  the missing multiple contributions with terms
                  involving auto-convolutions of the primary
                  wavefield. Exclusion of the unknown data as an
                  inversion variable from the REPSI process is
                  desireable, since it eliminates a significant source
                  of local minima that arises from attempting to
                  invert for the unobserved traces using primary and
                  multiple models that may be far-away from the true
                  solution. In this talk we investigate the necessary
                  modifications to the Robust EPSI algorithm to
                  account for the resulting non-linear modeling
                  operator, and demonstrate that just a few
                  auto-convolution terms are enough to satisfactorily
                  mitigate the effects of data gaps during the
                  inversion process.},
  keywords = {EPSI, REPSI, multiples, inversion, algorithm},
  note = {(to be presented at the SEG)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/SEG/2014/lin2014SEGmdg/lin2014SEGmdg.html}
}


@UNPUBLISHED{ghadermarzy2014SEGsti,
  author = {Navid Ghadermarzy and Ozgur Yilmaz and Felix J. Herrmann},
  title = {Seismic trace interpolation with approximate message passing},
  year = {2014},
  month = {04},
  institution = {UBC},
  abstract = {Approximate message passing (AMP) is a computationally
                  effective algorithm for recovering high dimensional
                  signals from a few compressed measurements. In this
                  paper we use AMP to solve the seismic trace
                  interpolation problem. We also show that we can
                  exploit the fast AMP algorithm to improve the
                  recovery results of seismic trace interpolation in
                  curvelet domain, both in terms of convergence speed
                  and recovery performance by using AMP in Fourier
                  domain as a preprocessor for the L1 recovery in
                  Curvelet domain.},
  keywords = {interpolation, AMP},
  note = {(to be presented at the SEG)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/SEG/2014/ghadermarzy2014SEGsti/ghadermarzy2014SEGsti.html}
}


@UNPUBLISHED{miao2014SEGrhss,
  author = {Lina Miao and Polina Zheglova and Felix J. Herrmann},
  title = {Randomized {HSS} acceleration for full-wave-equation depth stepping migration},
  year = {2014},
  month = {04},
  institution = {UBC},
  abstract = {In this work we propose to use the spectral projector
                  (Kenney and Laub, 1995) and randomized HSS technique
                  (Chandrasekaran et al., 2006) to achieve a stable
                  and affordable two-way wave equation depth stepping
                  migration algorithm.},
  keywords = {acoustic, randomized SVD, spectral projector, full wave equation migration, depth extrapolation},
  note = {(to be presented at the SEG)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/SEG/2014/miao2014SEGrhss/miao2014SEGrhss.html}
}


@UNPUBLISHED{oghenekohwo2014SEGrsw,
  author = {Felix Oghenekohwo and Rajiv Kumar and Felix J. Herrmann},
  title = {Randomized sampling without repetition in time-lapse surveys},
  year = {2014},
  month = {04},
  institution = {UBC},
  abstract = {Vouching for higher levels of repeatability in
                  acquisition and processing of time-lapse (4D)
                  seismic data has become the standard with oil and
                  gas contractor companies, with significant
                  investment in the design of acquisition systems and
                  processing algorithms that attempt to address some
                  of the current 4D challenges, in particular, imaging
                  weak 4D signals. Recent developments from the field
                  of compressive sensing have shown the benefits of
                  variants of randomized sampling in marine seismic
                  acquisition and its impact for the future of seismic
                  exploration. Following these developments, we show
                  that the requirement for accurate survey repetition
                  in time-lapse seismic data acquisition can be waived
                  provided we solve a sparsity-promoting convex
                  optimization program that makes use of the shared
                  component between the baseline and monitor data. By
                  setting up a framework for inversion of the stacked
                  sections of a time-lapse data, given the pre-stack
                  data volumes, we are able to extract 4D signals with
                  relatively highfidelity from significant
                  subsamplings. Our formulation is applied to
                  time-lapse data that has been acquired with
                  different source/receiver geometries, paving the way
                  for an efficient approach to dealing with time-lapse
                  data acquired with initially poor repeatability
                  levels, provided the survey geometry details are
                  known afterwards.},
  keywords = {acquisition, repetition, 4D, time-lapse, random},
  note = {(to be presented at the SEG)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/SEG/2014/oghenekohwo2014SEGrsw/oghenekohwo2014SEGrsw.html}
}


@UNPUBLISHED{peters2014SEGsrh,
  author = {Bas Peters and Felix J. Herrmann},
  title = {A sparse reduced Hessian approximation for multi-parameter wavefield reconstruction inversion},
  year = {2014},
  month = {04},
  institution = {UBC},
  abstract = {Multi-Parameter full-waveform inversion is a challenging
                  problem, because the unknown parameters appear in
                  the same wave equation and the magnitude of the
                  parameters can vary many orders of magnitude. This
                  makes accurate estimation of multiple-parameters
                  very difficult. To mitigate the problems, sequential
                  strategies, regularization methods and scalings of
                  gradients and quasi-Newton Hessians have been
                  proposed. All of these require design, fine-tuning
                  and adaptation to different waveform inversion
                  problems. We propose to use a sparse approximation
                  to the Hessian derived from a penalty-formulation of
                  the objective function. Sparseness allows to have
                  the Hessian in memory and compute update directions
                  at very low cost. This results in decent
                  reconstruction of the multiple parameters at very
                  low additional memory and computational expense.},
  keywords = {full-waveform inversion, optimization, Hessian, penalty method},
  note = {(to be presented at the SEG)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/SEG/2014/peters2014SEGsrh/peters2014SEGsrh.html}
}


@UNPUBLISHED{wason2014SEGrrt,
  author = {Haneet Wason and Felix Oghenekohwo and Felix J. Herrmann},
  title = {Randomization and repeatability in time-lapse marine acquisition},
  year = {2014},
  month = {04},
  institution = {UBC},
  abstract = {We present an extension of our time-jittered
                  simultaneous marine acquisition to time-lapse
                  surveys where the requirement for repeatability in
                  acquisition can be waived provided we know the
                  acquisition geometry afterwards. Our method, which
                  does not require repetition, gives 4-D signals
                  comparable to conventional methods where
                  repeatability is key to their success.},
  keywords = {marine, acquisition, time-laspe, deblending},
  note = {(to be presented at the SEG)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/SEG/2014/wason2014SEGrrt/wason2014SEGrrt.html}
}


@UNPUBLISHED{wason2014SEGsss,
  author = {Haneet Wason and Rajiv Kumar and Aleksandr Y. Aravkin and Felix J. Herrmann},
  title = {Source separation via {SVD}-free rank minimization in the hierarchical semi-separable representation},
  year = {2014},
  month = {04},
  institution = {UBC},
  abstract = {Recent developments in matrix rank optimization have
                  allowed for new computational approaches in the
                  field of source separation or deblending. In this
                  paper, we propose a source separation algorithm for
                  blended marine acquisition, where two sources are
                  deployed at different depths (over/under
                  acquisition). The separation method incorporates the
                  Hierarchical Semi-Separable structure (HSS) inside
                  rank-regularized least-squares formulations. The
                  proposed approach is suitable for large scale
                  problems, since it avoids SVD computations and uses
                  a low-rank factorized formulation instead. We
                  illustrate the performance of the new HSS-based
                  deblending approach by simulating an over/under
                  blended acquisition, wherein uniformly random time
                  delays (of < 1 second) are applied to one of the
                  sources.},
  keywords = {source separation, deblending, marine, acquisition, rank, HSS},
  note = {(to be presented at the SEG)},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Conferences/SEG/2014/wason2014SEGsss/wason2014SEGsss.html}
}


@UNPUBLISHED{tu2014fis,
  author = {Ning Tu and Felix J. Herrmann},
  title = {Fast imaging with surface-related multiples by sparse inversion},
  year = {2014},
  month = {04},
  institution = {UBC},
  abstract = {In marine exploration seismology, surface-related
                  multiples are usually treated as noise mainly
                  because subsequent processing steps, such as
                  migration-velocity analysis and imaging, require
                  multiple-free data. Failure to remove these
                  wavefield components from the data may lead to
                  erroneous estimates for migration velocity or result
                  in strong coherent artifacts that interfere with the
                  imaged reflectors. On the other hand, multiples
                  interact with the free surface and are therefore
                  exposed more to the subsurface. Hence, multiples
                  carry complementary information compared to the
                  primaries and when processed correctly improve the
                  illumination. Given a sufficiently accurate
                  background velocity model and an estimate for the
                  source signature, we propose a wave-equation based
                  inversion procedure that produces accurate images of
                  velocity perturbations in the subsurface from the
                  total upgoing wavefield including surface-related
                  multiples. Because our method uses subsampling
                  techniques, we obtain high-quality true-amplitude
                  least-squares migrated images at computational costs
                  of roughly a single reverse-time migration with
                  fully sampled data. We also incur a minimal overhead
                  from incorporating the multiples by having the
                  wave-equation solver carry out the
                  multiple-predictions via the inclusion of an areal
                  source. Our method derives its efficacy from
                  promoting curvelet-domain sparsity in the imaged
                  domain and leads to images that are virtually free
                  of artifacts from data that includes multiples. The
                  method is also relatively robust with respect to
                  linearization errors and errors in the background
                  velocity model.},
  keywords = {multiples, inversion, Kaczmarz, compressive sensing, curvelet, approximate message passing, private},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2014/tu2014fis/tu2014fis.pdf}
}


@UNPUBLISHED{vanLeeuwen20143Dfds,
  author = {Tristan van Leeuwen and Felix J. Herrmann},
  title = {{3D} frequency-domain seismic inversion with controlled sloppiness},
  year = {2014},
  month = {03},
  abstract = {Seismic waveform inversion aims at obtaining detailed
                  estimates of subsurface medium parameters, such as
                  the spatial distribution of soundspeed, from
                  multi-experiment seismic data. A formulation of this
                  inverse problem in the frequency-domain leads to an
                  optimization problem constrained by a Helmholtz
                  equation with many right-hand-sides. Application of
                  this technique to industry-scale problem faces
                  several challenges: Firstly, we need to solve the
                  Helmholtz equation for high wavenumbers over large
                  computational domains. Secondly, the data consists
                  of many independent experiments, leading to a large
                  number of PDE-solves. This results in high
                  computational complexity both in terms of memory and
                  CPU time as well as i/o costs. Finally, the inverse
                  problem is highly non-linear and a lot of art goes
                  into preprocessing and regularization. Ideally, an
                  inversion needs to be run several times with
                  different initial guesses and/or tuning
                  parameters. In this paper, we discuss the
                  requirements of the various components (PDE-solver,
                  optimization method, ...) when applied to
                  large-scale 3D seismic waveform inversion and
                  combine several existing approaches into a flexible
                  inversion scheme for seismic waveform inversion. The
                  scheme is based on the idea that in the early stages
                  of the inversion we do not need all the data or very
                  accurate PDE-solves. We base our method on an
                  existing preconditioned Krylov solver (CARP-CG) and
                  use ideas from stochastic optimization to formulate
                  a gradient-based (Quasi-Newton) optimization
                  algorithm that works with small subsets of the
                  right-hand-sides and uses inexact PDE solves for the
                  gradient calculations. We proposed novel heuristics
                  to adaptively control both the accuracy and the
                  number of right-hand-sides. We illustrate the
                  algorithms on synthetic benchmark models for which
                  significant computational gains can be made without
                  being sensitive to noise and without loosing
                  accuracy of the inverted model.},
  keywords = {waveform inversion, optimization},
  note = {to appear in the SIAM Journal on Scientific Computing (SISC)}, 
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Journals/SIAM_Journal_on_Scientific_Computing/2014/vanLeeuwen20143Dfds/vanLeeuwen20143Dfds.pdf}
}


%-----2013-----%

@UNPUBLISHED{ghadermarzy2013ncs,
  author = {Navid Ghadermarzy and Hassan Mansour and Ozgur Yilmaz},
  title = {Non-convex compressed sensing using partial support information},
  year = {2013},
  institution = {UBC},
  abstract = {In this paper we address the recovery conditions of
                  weighted $\ell_p$ minimization for signal reconstruction
                  from compressed sensing measurements when partial
                  support in- formation is available. We show that
                  weighted $\ell_p$ minimization with 0 < p < 1 is stable
                  and robust under weaker sufficient conditions
                  compared to weighted $\ell_1$ minimization. Moreover, the
                  sufficient recovery conditions of weighted $\ell_p$ are
                  weaker than those of regular $\ell_p$ minimization if at
                  least 50\% of the support estimate is accurate. We
                  also review some algorithms which exist to solve the
                  non-convex $\ell_p$ problem and illustrate our results
                  with numerical experiments.},
  keywords = {Compressed sensing, weighted $\ell_p$, nonconvex optimization, sparse reconstruction},
  month = {11},
  url = {http://arxiv.org/abs/1311.3773}
}


@UNPUBLISHED{aravkin2013SISCLR,
  author = {Aleksandr Y. Aravkin and Rajiv Kumar and Hassan Mansour and Ben Recht and Felix J. Herrmann},
  title = {Fast methods for denoising matrix completion formulations, with application to robust seismic data interpolation},
  year = {2013},
  month = {05},
  abstract = {Recent SVD-free matrix factorization formulations have
                  enabled rank minimization for systems with millions
                  of rows and columns, paving the way for matrix
                  completion in extremely large-scale applications,
                  such as seismic data interpolation. In this paper,
                  we consider matrix completion formulations designed
                  to hit a target data-fitting error level provided by
                  the user, and propose an algorithm called LR-BPDN
                  that is able to exploit factorized formulations to
                  solve the corresponding optimization problem. Since
                  practitioners typically have strong prior knowledge
                  about target error level, this innovation makes it
                  easy to apply the algorithm in practice, leaving
                  only the factor rank to be determined.  Within the
                  established framework, we propose two extensions
                  that are highly relevant to solving practical
                  challenges of data interpolation. First, we propose
                  a weighted extension that allows known subspace
                  information to improve the results of matrix
                  completion formulations. We show how this weighting
                  can be used in the context of frequency
                  continuation, an essential aspect to seismic data
                  interpolation. Second, we propose matrix completion
                  formulations that are robust to large measurement
                  errors in the available data. We illustrate the
                  advantages of LR-BPDN on the collaborative filtering
                  problem using the MovieLens 1M, 10M, and Netflix
                  100M datasets. Then, we use the new method, along
                  with its robust and subspace re-weighted extensions,
                  to obtain high-quality reconstructions for large
                  scale seismic interpolation problems with real data,
                  even in the presence of data contamination.},
  keywords = {interpolation, denoising, robust, SVD-free},
  url = {http://arxiv.org/abs/1302.4886} 
}

