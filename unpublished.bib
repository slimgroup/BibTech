% This file was created with JabRef 2.9.
% Encoding: MacRoman

%-----2014-----%

@UNPUBLISHED{tu2014fis,
  author = {Ning Tu and Felix J. Herrmann},
  title = {Fast imaging with surface-related multiples by sparse inversion},
  year = {2014},
  month = {04},
  institution = {UBC},
  abstract = {In marine exploration seismology, surface-related
                  multiples are usually treated as noise mainly
                  because subsequent processing steps, such as
                  migration-velocity analysis and imaging, require
                  multiple-free data. Failure to remove these
                  wavefield components from the data may lead to
                  erroneous estimates for migration velocity or result
                  in strong coherent artifacts that interfere with the
                  imaged reflectors. On the other hand, multiples
                  interact with the free surface and are therefore
                  exposed more to the subsurface. Hence, multiples
                  carry complementary information compared to the
                  primaries and when processed correctly improve the
                  illumination. Given a sufficiently accurate
                  background velocity model and an estimate for the
                  source signature, we propose a wave-equation based
                  inversion procedure that produces accurate images of
                  velocity perturbations in the subsurface from the
                  total upgoing wavefield including surface-related
                  multiples. Because our method uses subsampling
                  techniques, we obtain high-quality true-amplitude
                  least-squares migrated images at computational costs
                  of roughly a single reverse-time migration with
                  fully sampled data. We also incur a minimal overhead
                  from incorporating the multiples by having the
                  wave-equation solver carry out the
                  multiple-predictions via the inclusion of an areal
                  source. Our method derives its efficacy from
                  promoting curvelet-domain sparsity in the imaged
                  domain and leads to images that are virtually free
                  of artifacts from data that includes multiples. The
                  method is also relatively robust with respect to
                  linearization errors and errors in the background
                  velocity model.},
  keywords = {multiples, inversion, Kaczmarz, compressive sensing, curvelet, approximate message passing, private},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2014/tu2014fis/tu2014fis.pdf}
}


@UNPUBLISHED{vanLeeuwen20143Dfds,
  author   = {Tristan van Leeuwen and Felix J. Herrmann},
  title    = {3D frequency-domain seismic inversion with controlled sloppiness},
  year     = {2014},
  month    = {03},
  abstract = {Seismic waveform inversion aims at obtaining detailed
                  estimates of subsurface medium parameters, such as
                  the spatial distribution of soundspeed, from
                  multi-experiment seismic data. A formulation of this
                  inverse problem in the frequency-domain leads to an
                  optimization problem constrained by a Helmholtz
                  equation with many right-hand-sides. Application of
                  this technique to industry-scale problem faces
                  several challenges: Firstly, we need to solve the
                  Helmholtz equation for high wavenumbers over large
                  computational domains. Secondly, the data consists
                  of many independent experiments, leading to a large
                  number of PDE-solves. This results in high
                  computational complexity both in terms of memory and
                  CPU time as well as i/o costs. Finally, the inverse
                  problem is highly non-linear and a lot of art goes
                  into preprocessing and regularization. Ideally, an
                  inversion needs to be run several times with
                  different initial guesses and/or tuning
                  parameters. In this paper, we discuss the
                  requirements of the various components (PDE-solver,
                  optimization method, ...) when applied to
                  large-scale 3D seismic waveform inversion and
                  combine several existing approaches into a flexible
                  inversion scheme for seismic waveform inversion. The
                  scheme is based on the idea that in the early stages
                  of the inversion we do not need all the data or very
                  accurate PDE-solves. We base our method on an
                  existing preconditioned Krylov solver (CARP-CG) and
                  use ideas from stochastic optimization to formulate
                  a gradient-based (Quasi-Newton) optimization
                  algorithm that works with small subsets of the
                  right-hand-sides and uses inexact PDE solves for the
                  gradient calculations. We proposed novel heuristics
                  to adaptively control both the accuracy and the
                  number of right-hand-sides. We illustrate the
                  algorithms on synthetic benchmark models for which
                  significant computational gains can be made without
                  being sensitive to noise and without loosing
                  accuracy of the inverted model.},
  keywords = {waveform inversion, optimization},
  note = {to appear in the SIAM Journal on Scientific Computing (SISC)}, 
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Journals/SIAM_Journal_on_Scientific_Computing/2014/vanLeeuwen20143Dfds/vanLeeuwen20143Dfds.pdf}
}


%-----2013-----%

@UNPUBLISHED{ghadermarzy2013ncs,
  author   = {Navid Ghadermarzy and Hassan Mansour and Ozgur Yilmaz},
  title    = {Non-Convex compressed sensing using partial support information},
  year     = {2013},
  institution = {UBC},
  abstract = {In this paper we address the recovery conditions of
                  weighted $\ell_p$ minimization for signal reconstruction
                  from compressed sensing measurements when partial
                  support in- formation is available. We show that
                  weighted $\ell_p$ minimization with 0 < p < 1 is stable
                  and robust under weaker sufficient conditions
                  compared to weighted $\ell_1$ minimization. Moreover, the
                  sufficient recovery conditions of weighted $\ell_p$ are
                  weaker than those of regular $\ell_p$ minimization if at
                  least 50% of the support estimate is accurate. We
                  also review some algorithms which exist to solve the
                  non-convex $\ell_p$ problem and illustrate our results
                  with numerical experiments.},
  keywords = {Compressed sensing, weighted $\ell_p$, nonconvex optimization, sparse reconstruction},
  month = {11},
  url = {http://arxiv.org/abs/1311.3773}
}


@UNPUBLISHED{vanLeeuwen2013Penalty2,
  author   = {Tristan van Leeuwen and Felix J. Herrmann},
  title    = {A penalty method for PDE-constrained optimization},
  year     = {2013},
  institution = {UBC},
  abstract = {We present a method for solving PDE constrained
                  optimization problems based on a penalty
                  formulation. This method aims to combine advantages
                  of both full-space and reduced methods by exploiting
                  a large search-space (consisting of both control and
                  state variables) while allowing for an efficient
                  implementation that avoids storing and updating the
                  state-variables. This leads to a method that has
                  roughly the same per-iteration complexity as
                  conventional reduced approaches while dening an
                  objective that is less non-linear in the control
                  variable by implicitly relaxing the constraint. We
                  apply the method to a seismic inverse problem where
                  it leads to a particularly ecient implementation
                  when compared to a conventional reduced approach as
                  it avoids the use of adjoint
                  state-variables. Numerical examples illustrate the
                  approach and suggest that the proposed formulation
                  can indeed mitigate some of the well-known problems
                  with local minima in the seismic inverse problem.},
  keywords = {waveform inversion, optimization, private},
  month = {04},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2013/vanLeeuwen2013Penalty2/vanLeeuwen2013Penalty2.pdf}
}


@UNPUBLISHED{aravkin2013SISCLR,
  author = {Aleksandr Y. Aravkin and Rajiv Kumar and Hassan Mansour and Ben Recht and Felix J. Herrmann},
  title = {Fast methods for denoising matrix completion formulations, with application to robust seismic data interpolation},
  year = {2013},
  month = {05},
  abstract = {Recent SVD-free matrix factorization formulations have
                  enabled rank minimization for systems with millions
                  of rows and columns, paving the way for matrix
                  completion in extremely large-scale applications,
                  such as seismic data interpolation. In this paper,
                  we consider matrix completion formulations designed
                  to hit a target data-fitting error level provided by
                  the user, and propose an algorithm called LR-BPDN
                  that is able to exploit factorized formulations to
                  solve the corresponding optimization problem. Since
                  practitioners typically have strong prior knowledge
                  about target error level, this innovation makes it
                  easy to apply the algorithm in practice, leaving
                  only the factor rank to be determined.  Within the
                  established framework, we propose two extensions
                  that are highly relevant to solving practical
                  challenges of data interpolation. First, we propose
                  a weighted extension that allows known subspace
                  information to improve the results of matrix
                  completion formulations. We show how this weighting
                  can be used in the context of frequency
                  continuation, an essential aspect to seismic data
                  interpolation. Second, we propose matrix completion
                  formulations that are robust to large measurement
                  errors in the available data.  We illustrate the
                  advantages of LR-BPDN on the collaborative filtering
                  problem using the MovieLens 1M, 10M, and Netflix
                  100M datasets. Then, we use the new method, along
                  with its robust and subspace re-weighted extensions,
                  to obtain high-quality reconstructions for large
                  scale seismic interpolation problems with real data,
                  even in the presence of data contamination.},
  keywords = {interpolation, denoising, robust, SVD-free},
  url = {http://arxiv.org/abs/1302.4886} 
}


%-----2012-----%

@UNPUBLISHED{bander2012dre,
  author = {Bander Jumah and Felix J. Herrmann},
  title = {Dimensionality-reduced estimation of primaries by sparse inversion},
  year = {2012},
  abstract = {Data-driven methods---such as the estimation of primaries by sparse
	inversion---suffer from the 'curse of dimensionality' that leads
	to disproportional growth in computational and storage demands when
	moving to realistic 3D field data. To remove this fundamental impediment,
	we propose a dimensionality-reduction technique where the 'data matrix'
	is approximated adaptively by a randomized low-rank factorization.
	Compared to conventional methods, which need for each iteration passage
	through all data possibly requiring on-the-fly interpolation, our
	randomized approach has the advantage that the total number of passes
	is reduced to only one to three. In addition, the low-rank matrix
	factorization leads to considerable reductions in storage and computational
	costs of the matrix multiplies required by the sparse inversion.
	Application of the proposed method to synthetic and real data shows
	that significant performance improvements in speed and memory use
	are achievable at a low computational up-front cost required by the
	low-rank factorization.},
  keywords = {multiples,Processing,Optimization},
  month = {02},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/Journal/bander2012dre/bander2012dre.pdf}
}


@UNPUBLISHED{mansour12iwr,
  author = {Hassan Mansour and Felix J. Herrmann and Ozgur Yilmaz},
  title = {Improved wavefield reconstruction from randomized sampling via weighted
	one-norm minimization},
  year = {2012},
  abstract = {Missing-trace interpolation aims to recover the gaps caused by physical
	obstacles or deliberate subsampling to control acquisition costs
	in otherwise regularly-sampled seismic wavefields. While transform-domain
	sparsity promotion has proven to be an effective tool to solve this
	recovery problem, current recovery techniques make no use of a priori
	information on the locations of transform-domain coefficients. In
	this paper, we propose recovery by weighted one-norm minimization,
	which exploits correlations between the locations of significant
	coefficients of different partitions, e.g., shot records, common-offset
	gathers, or frequency slices of the acquired data. We use these correlations
	to define a sequence of 2D curvelet-based recovery problems that
	exploit 3D continuity exhibited by seismic wavefields without relying
	on the highly redundant 3D curvelet transform. To illustrate the
	performance of our weighted algorithm, we compare recoveries from
	different scenarios of partitioning for a seismic line from the Gulf
	of Suez. These examples demonstrate that our method is superior to
	standard $\ell_1$ minimization in terms of reconstruction quality
	and computational memory requirements.},
  keywords = {Trace interpolation, weighted one-norm minimization, compressed sensing,
	randomized sampling},
  month = {10},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/Journal/mansour2012iwr/mansour2012iwr.pdf}
}


@UNPUBLISHED{vanleeuwen2012smii,
  author = {Tristan {van Leeuwen}},
  title = {A parallel matrix-free framework for frequency-domain seismic modelling,
	imaging and inversion in Matlab},
  year = {2012},
  abstract = {I present a parallel matrix-free framework for frequency-domain seismic
	modeling, imaging and inversion. The framework provides basic building
	blocks for designing and testing optimization-based formulations
	of both linear and non-linear seismic in- verse problems. By overloading
	standard linear-algebra operations, such as matrix- vector multiplications,
	standard optimization packages can be used to work with the code
	without any modification. This leads to a scalable testbed on which
	new methods can be rapidly prototyped and tested on medium-sized
	2D problems. I present some numerical examples on both linear and
	non-linear seismic inverse problems.},
  keywords = {Seismic imaging,optimization,Matlab,object-oriented programming},
  month = {07},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/Journal/vanleeuwen2012smii/vanleeuwen2012smii.pdf}
}

