% This file was created with JabRef 2.6.
% Encoding: MacRoman

@unpublished{vanleeuwen2012smii,
author = {Tristan {van Leeuwen}},
year = {2012},
optmonth = {07/2012},
title = {A parallel matrix-free framework for frequency-domain seismic modelling, imaging and inversion in Matlab},
abstract = {I present a parallel matrix-free framework for
                  frequency-domain seismic modeling, imaging and
                  inversion. The framework provides basic building
                  blocks for designing and testing optimization-based
                  formulations of both linear and non-linear seismic
                  in- verse problems. By overloading standard
                  linear-algebra operations, such as matrix- vector
                  multiplications, standard optimization packages can
                  be used to work with the code without any
                  modification. This leads to a scalable testbed on
                  which new methods can be rapidly prototyped and
                  tested on medium-sized 2D problems. I present some
                  numerical examples on both linear and non-linear
                  seismic inverse problems.},
keywords = {Seismic imaging,optimization,Matlab,object-oriented programming},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/Journal/vanleeuwen2012smii/vanleeuwen2012smii.pdf}
}


@unpublished{aravkin2012IPNuisance,
author = {Aleksandr Y. Aravkin and Tristan {van Leeuwen}},
year = {2012},
optmonth = {06/2012},
title = {Estimating Nuisance Parameters in Inverse Problems},
abstract = {Many inverse problems include nuisance parameters which,
                  while not of direct interest, are required to
                  recover primary parameters. Structure present in
                  these problems allows efficient optimization
                  strategies - a well known example is variable
                  projection, where nonlinear least squares problems
                  which are linear in some parameters can be very
                  efficiently optimized. In this paper, we extend the
                  idea of projecting out a subset over the variables
                  to a broad class of maximum likelihood (ML) and
                  maximum a posteriori likelihood (MAP) problems with
                  nuisance parameters, such as variance or degrees of
                  freedom. As a result, we are able to incorporate
                  nuisance parameter estimation into large-scale
                  constrained and unconstrained inverse problem
                  formulations. We apply the approach to a variety of
                  problems, including estimation of unknown variance
                  parameters in the Gaussian model, degree of freedom
                  (d.o.f.) parameter estimation in the context of
                  robust inverse problems, automatic calibration, and
                  optimal experimental design. Using numerical
                  examples, we demonstrate improvement in recovery of
                  primary parameters for several large- scale inverse
                  problems. The proposed approach is compatible with a
                  wide variety of algorithms and formulations, and its
                  implementation requires only minor modifications to
                  existing algorithms.},
keywords = {full waveform inversion, students t, variance},
url = {http://arxiv.org/abs/1206.6532}
}

@unpublished{lin2012robustepsi,
author = {Tim T.Y. Lin and Felix J. Herrmann},
year = {2012},
optmonth = {03/2012},
title = {Robust estimation of primaries by sparse inversion via one-norm minimization},
abstract = {Even though contemporary methods for the removal of multiple 
events in seismic data due to a free-surface are built upon reciprocity 
relationships between wavefields, they are often still implemented as 
prediction-subtraction processes. The subtraction process does not always 
compensate for imperfect prediction of multiple events, and itself often 
leads to distortion of primary events. A recently proposed method called 
Estimation of Primaries by Sparse Inversion avoids the subtraction process 
altogether by directly prediction the primary impulse response as a collection 
of band-limited spikes under sparsity-regulated wavefield inversion approach. 
Although it can be shown that the correct primary impulse response is 
obtained through the sparsest possible solution, the Estimation of Primaries 
by Sparse Inversion algorithm was not designed to seek such a solution, instead 
depending on a predetermined degree of sparsity as an inversion parameter. 
This leads to imperfect multiple rejection when the sparsity is overestimated, 
and problems with recovering late primary events when it is underestimated. 
In this paper, we propose a new algorithm where we make obtaining the 
sparsest solution our explicit goal. Our approach remains a gradient-based 
approach like the original algorithm, but is in turn derived from a new 
optimization framework based on an extended basis pursuit denoising formulation. 
We show that the sparsity-minimizing objective of our formulation enables it 
to operate successfully on a wide variety of synthetic and field marine dataset 
without excessive tweaking of inversion parameters. We also demonstrate that 
Robust EPSI produces a more artifact-free impulse response compared to the 
original algorithm, which has interesting implications for broadband seismic 
applications. Finally we demonstrate through field data that recovering the 
primary impulse response under transform domains can significantly improve 
the recovery of weak primary late arrivals, without appreciable change to the 
underlying algorithm.},
keywords = {multiples, optimization, sparsity, waveform inversion, pareto, biconvex, algorithm, EPSI},
notes = {submitted to Geophysics, March 12, 2012},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/Journal/lin2012robustepsi/lin2012robustepsi.pdf}
}

@unpublished{bander2012dre,
author = {Bander Jumah and Felix J. Herrmann},
year = {2012},
optmonth = {02/2012},
title = {Dimensionality-reduced estimation of primaries by sparse inversion},
abstract = {Data-driven methods---such as the estimation of primaries by sparse 
inversion---suffer from the 'curse of dimensionality' that leads to 
disproportional growth in computational and storage demands when 
moving to realistic 3D field data. To remove this fundamental 
impediment, we propose a dimensionality-reduction technique where 
the 'data matrix' is approximated adaptively by a randomized 
low-rank factorization. Compared to conventional methods, which need 
for each iteration passage through all data possibly requiring 
on-the-fly interpolation, our randomized approach has the advantage 
that the total number of passes is reduced to only one to three. In 
addition, the low-rank matrix factorization leads to considerable 
reductions in storage and computational costs of the matrix 
multiplies required by the sparse inversion. Application of the 
proposed method to synthetic and real data shows that significant 
performance improvements in speed and memory use are achievable at a 
low computational up-front cost required by the low-rank 
factorization.},
keywords = {multiples,Processing,Optimization},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/Journal/bander2012dre/bander2012dre.pdf}
}

@unpublished{min2012CSEGrgfe,
author = {Ju-Won Oh and Dong-Joo Min and Felix J. Herrmann},
year = {2012},
optmonth = {02/2012},
title = {Re-establishment of gradient in frequency-domain elastic waveform inversion},
abstract = {To obtain solutions close to global minimum in waveform 
inversion, the gradients computed at each frequency need to be 
weighted to appropriately describe the residuals between modeled and 
field data. While the low-frequency components of the gradients should 
be weighted to recover the long- wavelength structures, the high-frequency 
components of the gradients need to be weighted when the short-wavelength 
structures are restored. However, the conventional elastic waveform inversion 
algorithms cannot properly weight the gradients computed at each frequency. 
When gradients are scaled using the pseudo-Hessian matrix inside the 
frequency loop, gradients obtained at high frequencies are over-emphasized. 
When the gradients are scaled outside the frequency loop, gradients are 
weighted by the source spectra. In this study, we propose applying weighting 
factors to the gradients obtained at each frequency so that gradients can 
properly reflect the differences between the true and assumed models satisfying 
the general inverse theory. The weighting factors are composed by the 
backpropagated residuals. Numerical examples for the simple rectangular-shaped 
model and the modified version of the Marmousi-2 model show that the 
weighting method enhances gradient images and inversion results compared 
to the conventional inversion algorithms.},
keywords = {elastic, waveform inversion, frequency-domain, weighting factors},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/CSEG/2012/min2012CSEGrgfe/min2012CSEGrgfe.pdf}
}

@unpublished{wason2012CSEGode,
author = {Haneet Wason and Felix J. Herrmann},
year = {2012},
optmonth = {02/2012},
title = {Only dither: efficient simultaneous marine acquisition},
abstract = {Simultaneous-source acquisition is an emerging technology
that is stimulating both geophysical research and commercial efforts. 
Simultaneous marine acquisition calls for the development of a new set
of design principles and post-processing tools. The focus here is on 
simultaneous-source marine acquisition design and sparsity-promoting 
sequential-source data recovery. We propose a pragmatic simultaneous-source, 
randomized marine acquisition scheme where multiple vessels sail across 
an ocean-bottom array firing airguns at — sequential locations and randomly 
time-dithered instances. By leveraging established findings from the field of 
compressive sensing, where the choice of the sparsifying transform needs 
to be incoherent with the compressive sampling matrix, we can significantly 
impact the reconstruction quality, and demonstrate that the compressive 
sampling matrix resulting from the proposed sampling scheme is sufficiently 
incoherent with the curvelet transform to yield successful recovery by sparsity 
promotion. Results are illustrated with simulations of “purely” random marine 
acquisition, which requires an airgun to be located at each source location, 
and random time-dithering marine acquisition with one and two source vessels. 
Size of the collected data volumes in all cases is the same. Compared to the 
recovery from the former acquisition scheme (SNR = 10.5dB), we get good 
results by dithering with only one source vessel (SNR = 8.06dB) in the latter 
scheme, which improve at the cost of having an additional source vessel 
(SNR = 9.85dB).},
keywords = {CSEG, acquisition, marine, simultaneous},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/CSEG/2012/wason2012CSEGode/wason2012CSEGode.pdf}
}

@unpublished{li2011CSEGefimag,
author = {Xiang Li and Felix J. Herrmann},
year = {2012},
optmonth = {02/2012},
title = {Efficient full-waveform inversion with marine acquisition geometry},
abstract = {Full-waveform inversion (FWI) is a nonlinear data fitting procedure 
based on seismic data to derive a accurate velocity model. With the increasing 
demand for high resolution images in complex geological settings, the 
importance of improvements in acquisition and inversion become more and 
more critical. However, these improvements will be obtained at high 
computational cost, as a typical marine survey contains thousands of shot 
and receiver positions, and FWI needs several passes through massive seismic 
data. Computational cost of FWI will grow exponentially as the size of seismic 
data and desired resolution increase. In this paper we present a modified 
Gauss-Newton (GN) method that borrows ideas from compressive sensing, 
where we compute the GN updates from a few randomly selected sequential 
shots. Each subproblem is solved by using a sparsity promoting algorithm. 
With this approach, we dramatically reduce the size and hence the 
computational costs of the problem, whilst we control information loss by 
redrawing a different set of sequential shots for each subproblem.},
keywords = {CSEG},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/CSEG/2012/li2011CSEGefimag/li2011CSEGefimag.pdf}
}


@unpublished{Friedlander11TRhdm,
  author = {Michael P. Friedlander and Mark Schmidt},
  title = {Hybrid deterministic-stochastic methods for data fitting},
  institution = {Department of Computer Science},
  year = {2011},
  address = {University of British Columbia, Vancouver},
  optmonth = {04/2011},
  abstract = {Many structured data-fitting applications require the
                  solution of an optimization problem involving a sum
                  over a potentially large number of
                  measurements. Incremental gradient algorithms (both
                  deterministic and randomized) offer inexpensive
                  iterations by sampling only subsets of the terms in
                  the sum. These methods can make great progress
                  initially, but often slow as they approach a
                  solution. In contrast, full gradient methods achieve
                  steady convergence at the expense of evaluating the
                  full objective and gradient on each iteration. We
                  explore hybrid methods that exhibit the benefits of
                  both approaches. Rate of convergence analysis and
                  numerical experiments illustrate the potential for
                  the approach.},
  publisher = {Department of Computer Science},
  keywords ={Optimization},
  url = {http://www.cs.ubc.ca/~mpf/papers/FriedlanderSchmidt2011.pdf}
}

@unpublished{Mansour11TRwmmw,
  author = {Hassan Mansour and Ozgur Yilmaz.},
  title = {Weighted -$\ell_1$ minimization with multiple weighting sets},
  year = {2011},
  type = {Tech. Rep.},
  address = {University of British Columbia, Vancouver},
  optmonth = {09/2011},
notes= {TR-2011-07 },
  abstract = {In this paper, we study the support In this paper, we
                  study the support recovery conditions of weighted
                  -$\ell_1$ minimization for signal reconstruction
                  from compressed sensing measurements when multiple
                  support estimate sets with different accuracy are
                  available. We identify a class of signals for which
                  the recovered vector from -$\ell_1$ minimization
                  provides an accurate support estimate. We then
                  derive stability and robustness guarantees for the
                  weighted -$\ell_1$ minimization problem with more
                  than one support estimate. We show that applying a
                  smaller weight to support estimate that enjoy higher
                  accuracy improves the recovery conditions compared
                  with the case of a single support estimate and the
                  case with standard, i.e., non-weighted,-$\ell_1$
                  minimization. Our theoretical results are supported
                  by numerical simulations on synthetic signals and
                  real audio signals.},
keywords={Compressive Sensing,Optimization},
  url = {http://slim.eos.ubc.ca/Publications/private/Journals/MansourYilmaz2011.pdf }
}

% Check with Michael whether this will be publsihed or stays as an technical report
@unpublished{vandenberg08gsv,
  author = {Ewout {van den Berg} and Mark Schmidt and Michael P. Friedlander and K.
	Murphy},
  title = {Group sparsity via linear-time projection},
institution = {UBC-Computer Science Department},
  year = {2008},
    number = {TR-2008-1},
  abstract = {We present an efficient spectral projected-gradient algorithm for
	optimization subject to a group one-norm constraint. Our approach
	is based on a novel linear-time algorithm for Euclidean projection
	onto the one- and group one-norm constraints. Numerical experiments
	on large data sets suggest that the proposed method is substantially
	more efficient and scalable than existing methods.},
  keywords = {SLIM,Optimization},
  url = {http://www.optimization-online.org/DB_FILE/2008/07/2056.pdf}
}

