% This file was created with JabRef 2.6.
% Encoding: MacRoman

@unpublished{vanleeuwen2012smii,
author = {Tristan {van Leeuwen}},
year = {2012},
optmonth = {07/2012},
title = {A parallel matrix-free framework for frequency-domain seismic modelling, imaging and inversion in Matlab},
abstract = {I present a parallel matrix-free framework for
                  frequency-domain seismic modeling, imaging and
                  inversion. The framework provides basic building
                  blocks for designing and testing optimization-based
                  formulations of both linear and non-linear seismic
                  in- verse problems. By overloading standard
                  linear-algebra operations, such as matrix- vector
                  multiplications, standard optimization packages can
                  be used to work with the code without any
                  modification. This leads to a scalable testbed on
                  which new methods can be rapidly prototyped and
                  tested on medium-sized 2D problems. I present some
                  numerical examples on both linear and non-linear
                  seismic inverse problems.},
keywords = {Seismic imaging,optimization,Matlab,object-oriented programming},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/Journal/vanleeuwen2012smii/vanleeuwen2012smii.pdf}
}


@unpublished{aravkin2012IPNuisance,
author = {Aleksandr Y. Aravkin and Tristan {van Leeuwen}},
year = {2012},
optmonth = {06/2012},
title = {Estimating Nuisance Parameters in Inverse Problems},
abstract = {Many inverse problems include nuisance parameters which,
                  while not of direct interest, are required to
                  recover primary parameters. Structure present in
                  these problems allows efficient optimization
                  strategies - a well known example is variable
                  projection, where nonlinear least squares problems
                  which are linear in some parameters can be very
                  efficiently optimized. In this paper, we extend the
                  idea of projecting out a subset over the variables
                  to a broad class of maximum likelihood (ML) and
                  maximum a posteriori likelihood (MAP) problems with
                  nuisance parameters, such as variance or degrees of
                  freedom. As a result, we are able to incorporate
                  nuisance parameter estimation into large-scale
                  constrained and unconstrained inverse problem
                  formulations. We apply the approach to a variety of
                  problems, including estimation of unknown variance
                  parameters in the Gaussian model, degree of freedom
                  (d.o.f.) parameter estimation in the context of
                  robust inverse problems, automatic calibration, and
                  optimal experimental design. Using numerical
                  examples, we demonstrate improvement in recovery of
                  primary parameters for several large- scale inverse
                  problems. The proposed approach is compatible with a
                  wide variety of algorithms and formulations, and its
                  implementation requires only minor modifications to
                  existing algorithms.},
keywords = {full waveform inversion, students t, variance},
url = {http://arxiv.org/abs/1206.6532}
}

@unpublished{lin2012robustepsi,
author = {Tim T.Y. Lin and Felix J. Herrmann},
year = {2012},
optmonth = {03/2012},
title = {Robust estimation of primaries by sparse inversion via one-norm minimization},
abstract = {Even though contemporary methods for the removal of multiple 
events in seismic data due to a free-surface are built upon reciprocity 
relationships between wavefields, they are often still implemented as 
prediction-subtraction processes. The subtraction process does not always 
compensate for imperfect prediction of multiple events, and itself often 
leads to distortion of primary events. A recently proposed method called 
Estimation of Primaries by Sparse Inversion avoids the subtraction process 
altogether by directly prediction the primary impulse response as a collection 
of band-limited spikes under sparsity-regulated wavefield inversion approach. 
Although it can be shown that the correct primary impulse response is 
obtained through the sparsest possible solution, the Estimation of Primaries 
by Sparse Inversion algorithm was not designed to seek such a solution, instead 
depending on a predetermined degree of sparsity as an inversion parameter. 
This leads to imperfect multiple rejection when the sparsity is overestimated, 
and problems with recovering late primary events when it is underestimated. 
In this paper, we propose a new algorithm where we make obtaining the 
sparsest solution our explicit goal. Our approach remains a gradient-based 
approach like the original algorithm, but is in turn derived from a new 
optimization framework based on an extended basis pursuit denoising formulation. 
We show that the sparsity-minimizing objective of our formulation enables it 
to operate successfully on a wide variety of synthetic and field marine dataset 
without excessive tweaking of inversion parameters. We also demonstrate that 
Robust EPSI produces a more artifact-free impulse response compared to the 
original algorithm, which has interesting implications for broadband seismic 
applications. Finally we demonstrate through field data that recovering the 
primary impulse response under transform domains can significantly improve 
the recovery of weak primary late arrivals, without appreciable change to the 
underlying algorithm.},
keywords = {multiples, optimization, sparsity, waveform inversion, pareto, biconvex, algorithm, EPSI},
notes = {submitted to Geophysics, March 12, 2012},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/Journal/lin2012robustepsi/lin2012robustepsi.pdf}
}

@unpublished{bander2012dre,
author = {Bander Jumah and Felix J. Herrmann},
year = {2012},
optmonth = {02/2012},
title = {Dimensionality-reduced estimation of primaries by sparse inversion},
abstract = {Data-driven methods---such as the estimation of primaries by sparse 
inversion---suffer from the 'curse of dimensionality' that leads to 
disproportional growth in computational and storage demands when 
moving to realistic 3D field data. To remove this fundamental 
impediment, we propose a dimensionality-reduction technique where 
the 'data matrix' is approximated adaptively by a randomized 
low-rank factorization. Compared to conventional methods, which need 
for each iteration passage through all data possibly requiring 
on-the-fly interpolation, our randomized approach has the advantage 
that the total number of passes is reduced to only one to three. In 
addition, the low-rank matrix factorization leads to considerable 
reductions in storage and computational costs of the matrix 
multiplies required by the sparse inversion. Application of the 
proposed method to synthetic and real data shows that significant 
performance improvements in speed and memory use are achievable at a 
low computational up-front cost required by the low-rank 
factorization.},
keywords = {multiples,Processing,Optimization},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/Journal/bander2012dre/bander2012dre.pdf}
}

@unpublished{min2012CSEGrgfe,
author = {Ju-Won Oh and Dong-Joo Min and Felix J. Herrmann},
year = {2012},
optmonth = {02/2012},
title = {Re-establishment of gradient in frequency-domain elastic waveform inversion},
abstract = {To obtain solutions close to global minimum in waveform 
inversion, the gradients computed at each frequency need to be 
weighted to appropriately describe the residuals between modeled and 
field data. While the low-frequency components of the gradients should 
be weighted to recover the long- wavelength structures, the high-frequency 
components of the gradients need to be weighted when the short-wavelength 
structures are restored. However, the conventional elastic waveform inversion 
algorithms cannot properly weight the gradients computed at each frequency. 
When gradients are scaled using the pseudo-Hessian matrix inside the 
frequency loop, gradients obtained at high frequencies are over-emphasized. 
When the gradients are scaled outside the frequency loop, gradients are 
weighted by the source spectra. In this study, we propose applying weighting 
factors to the gradients obtained at each frequency so that gradients can 
properly reflect the differences between the true and assumed models satisfying 
the general inverse theory. The weighting factors are composed by the 
backpropagated residuals. Numerical examples for the simple rectangular-shaped 
model and the modified version of the Marmousi-2 model show that the 
weighting method enhances gradient images and inversion results compared 
to the conventional inversion algorithms.},
keywords = {elastic, waveform inversion, frequency-domain, weighting factors},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/CSEG/2012/min2012CSEGrgfe/min2012CSEGrgfe.pdf}
}

@unpublished{wason2012CSEGode,
author = {Haneet Wason and Felix J. Herrmann},
year = {2012},
optmonth = {02/2012},
title = {Only dither: efficient simultaneous marine acquisition},
abstract = {Simultaneous-source acquisition is an emerging technology
that is stimulating both geophysical research and commercial efforts. 
Simultaneous marine acquisition calls for the development of a new set
of design principles and post-processing tools. The focus here is on 
simultaneous-source marine acquisition design and sparsity-promoting 
sequential-source data recovery. We propose a pragmatic simultaneous-source, 
randomized marine acquisition scheme where multiple vessels sail across 
an ocean-bottom array firing airguns at — sequential locations and randomly 
time-dithered instances. By leveraging established findings from the field of 
compressive sensing, where the choice of the sparsifying transform needs 
to be incoherent with the compressive sampling matrix, we can significantly 
impact the reconstruction quality, and demonstrate that the compressive 
sampling matrix resulting from the proposed sampling scheme is sufficiently 
incoherent with the curvelet transform to yield successful recovery by sparsity 
promotion. Results are illustrated with simulations of “purely” random marine 
acquisition, which requires an airgun to be located at each source location, 
and random time-dithering marine acquisition with one and two source vessels. 
Size of the collected data volumes in all cases is the same. Compared to the 
recovery from the former acquisition scheme (SNR = 10.5dB), we get good 
results by dithering with only one source vessel (SNR = 8.06dB) in the latter 
scheme, which improve at the cost of having an additional source vessel 
(SNR = 9.85dB).},
keywords = {CSEG, acquisition, marine, simultaneous},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/CSEG/2012/wason2012CSEGode/wason2012CSEGode.pdf}
}

@unpublished{li2011CSEGefimag,
author = {Xiang Li and Felix J. Herrmann},
year = {2012},
optmonth = {02/2012},
title = {Efficient full-waveform inversion with marine acquisition geometry},
abstract = {Full-waveform inversion (FWI) is a nonlinear data fitting procedure 
based on seismic data to derive a accurate velocity model. With the increasing 
demand for high resolution images in complex geological settings, the 
importance of improvements in acquisition and inversion become more and 
more critical. However, these improvements will be obtained at high 
computational cost, as a typical marine survey contains thousands of shot 
and receiver positions, and FWI needs several passes through massive seismic 
data. Computational cost of FWI will grow exponentially as the size of seismic 
data and desired resolution increase. In this paper we present a modified 
Gauss-Newton (GN) method that borrows ideas from compressive sensing, 
where we compute the GN updates from a few randomly selected sequential 
shots. Each subproblem is solved by using a sparsity promoting algorithm. 
With this approach, we dramatically reduce the size and hence the 
computational costs of the problem, whilst we control information loss by 
redrawing a different set of sequential shots for each subproblem.},
keywords = {CSEG},
url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/CSEG/2012/li2011CSEGefimag/li2011CSEGefimag.pdf}
}


@unpublished{Friedlander11TRhdm,
  author = {Michael P. Friedlander and Mark Schmidt},
  title = {Hybrid deterministic-stochastic methods for data fitting},
  institution = {Department of Computer Science},
  year = {2011},
  address = {University of British Columbia, Vancouver},
  optmonth = {04/2011},
  abstract = {Many structured data-fitting applications require the
                  solution of an optimization problem involving a sum
                  over a potentially large number of
                  measurements. Incremental gradient algorithms (both
                  deterministic and randomized) offer inexpensive
                  iterations by sampling only subsets of the terms in
                  the sum. These methods can make great progress
                  initially, but often slow as they approach a
                  solution. In contrast, full gradient methods achieve
                  steady convergence at the expense of evaluating the
                  full objective and gradient on each iteration. We
                  explore hybrid methods that exhibit the benefits of
                  both approaches. Rate of convergence analysis and
                  numerical experiments illustrate the potential for
                  the approach.},
  publisher = {Department of Computer Science},
  keywords ={Optimization},
  url = {http://www.cs.ubc.ca/~mpf/papers/FriedlanderSchmidt2011.pdf}
}

@unpublished{Mansour11TRwmmw,
  author = {Hassan Mansour and Ozgur Yilmaz.},
  title = {Weighted -$\ell_1$ minimization with multiple weighting sets},
  year = {2011},
  type = {Tech. Rep.},
  address = {University of British Columbia, Vancouver},
  optmonth = {09/2011},
notes= {TR-2011-07 },
  abstract = {In this paper, we study the support In this paper, we
                  study the support recovery conditions of weighted
                  -$\ell_1$ minimization for signal reconstruction
                  from compressed sensing measurements when multiple
                  support estimate sets with different accuracy are
                  available. We identify a class of signals for which
                  the recovered vector from -$\ell_1$ minimization
                  provides an accurate support estimate. We then
                  derive stability and robustness guarantees for the
                  weighted -$\ell_1$ minimization problem with more
                  than one support estimate. We show that applying a
                  smaller weight to support estimate that enjoy higher
                  accuracy improves the recovery conditions compared
                  with the case of a single support estimate and the
                  case with standard, i.e., non-weighted,-$\ell_1$
                  minimization. Our theoretical results are supported
                  by numerical simulations on synthetic signals and
                  real audio signals.},
keywords={Compressive Sensing,Optimization},
  url = {http://slim.eos.ubc.ca/Publications/private/Journals/MansourYilmaz2011.pdf }
}

@unpublished{Mansour11TRssma,
  author = {Hassan Mansour and Haneet Wason and Tim T.Y. Lin and Felix J. Herrmann},
  title = {Simultaneous-source marine acquisition with compressive sampling
        matrices},
  year = {2011},
notes= { TR-2011-04 },
  type = {Tech. Rep.},
  address = {University of British Columbia, Vancouver},
  optmonth = {08/2011},
  abstract = {Seismic data acquisition in marine environments is a
                  costly process that compels the adoption of
                  simultaneous-source acquisition - an emerging
                  technology that is stimu- lating both geophysical
                  research and commercial efforts. In this paper, we
                  discuss the properties of randomized simultaneous
                  acquisition matrices and demonstrate that
                  sparsity-promoting recovery improves the quality of
                  the reconstructed seismic data volumes. Leveraging
                  established findings from the field of compressive
                  sensing, we demonstrate that the choice of the
                  sparsifying transform that is incoherent with the
                  compressive sampling matrix can significantly impact
                  the reconstruction quality. Si- multaneous marine
                  acquisition calls for the development of a new set
                  of design principles and post-processing tools. We
                  propose to use random time dithering where
                  sequential acquisition with a single airgun is
                  replaced by continuous acquisition with multiple
                  airguns firing at random times and at random
                  locations. We then demonstrate that the resulting
                  compressive sampling matrix is incoherent with the
                  curvelet transform and the combined measurement
                  matrix exhibits better isometry properties than
                  other transform bases such as a non-localized
                  multidimensional Fourier transform. We il- lustrate
                  our results with simulations of simultaneous-source
                  marine acquisition using periodic and randomized
                  time dithering.},
  keywords ={SLIM,Acquisition,Processing,Compressive Sensing},
  url = {http://slim.eos.ubc.ca/Publications/Private/Journals/simmarineacq.pdf}
}

@unpublished{VanLeeuwen11TRfwiwse,
  author = {Tristan van Leeuwen and Felix J. Herrmann},
  title = {Fast waveform inversion without source encoding},
  year = {2011},
  type = {Tech. Rep.},
notes = {TR-2011-06 },
  address = {University of British Columbia, Vancouver},
  optmonth = {09/2011},
  abstract = {Randomized source encoding has recently been proposed as
                  a way to dramatically reduce the costs of full
                  waveform inversion. The main idea is to replace all
                  sequential sources by a small number of simultaneous
                  sources. This introduces random crosstalk in the
                  model updates and special stochastic optimization
                  strategies are required to deal with this. Two
                  problems arise with this approach: i) source
                  encoding can only be applied to fixed-spread
                  acquisition setups, and ii) stochastic optimization
                  methods tend to converge very slowly, relying on
                  averaging to get rid of the cross-talk. Although the
                  slow convergence is partly offset by the low
                  iteration cost, we show that conventional
                  optimization strategies are bound to outperform
                  stochastic methods in the long run. In this paper we
                  argue that we don¬øt need randomized source encoding
                  to reap the benefits of stochastic optimization and
                  we review an optimization strategy that combines the
                  benefits of both conventional and stochastic
                  optimization. The method uses a gradually increasing
                  batch of sources. Thus, iterations are very cheap
                  initially and this allows the method to make fast
                  progress in the beginning. As the batch size grows,
                  the method behaves like conventional optimization,
                  allowing for fast convergence. Numerical examples
                  suggest that the stochastic and hybrid method
                  perform equally well with and without source
                  encoding and that the hybrid method outperforms both
                  conventional and stochastic optimization. The method
                  does not rely on source encoding techniques and can
                  thus be applied to non fixed-spread data.},
  keywords = {SLIM,Full-waveform inversion,Optimization},
  url = {http://slim.eos.ubc.ca/Publications/private/Journals/TR201106.pdf }
}

@unpublished{Li11TRfrfwi,
  author = {Xiang Li and Aleksandr Y. Aravkin and Tristan van Leeuwen and Felix
        J. Herrmann},
  title = {Fast randomized full-waveform inversion with compressive sensing},
  year = {2011},
notes = {to appear in Geophysics},
  address = {University of British Columbia, Vancouver},
  optmonth = {10/2011},
  abstract = { Wave-equation based seismic inversion can be formulated
                  as a nonlinear inverse problem where the medium
                  properties are obtained via minimization of a least-
                  squares misfit functional. The demand for higher
                  resolution models in more geologically complex areas
                  drives the need to develop techniques that explore
                  the special structure of full-waveform inversion to
                  reduce the computational burden and to regularize
                  the inverse problem. We meet these goals by using
                  ideas from compressive sensing and stochastic
                  optimization to design a novel Gauss-Newton method,
                  where the updates are computed from random subsets
                  of the data via curvelet-domain sparsity
                  promotion. Application of this idea to a realistic
                  synthetic shows improved results compared to
                  quasi-Newton methods, which require passes through
                  all data. Two different subset sampling strategies
                  are considered: randomized source encoding, and
                  drawing sequential shots firing at random source
                  locations from marine data with missing near and far
                  offsets. In both cases, we obtain excellent
                  inversion results compared to conventional methods
                  at reduced computational costs. },
  keywords ={SLIM,Full-waveform inversion,Compressive Sensing,Optimization},
  url = {https://www.slim.eos.ubc.ca/Publications/Public/Submitted/Geophysics/Li11TRfrfwi/Li11TRfrfwi.pdf}
}

@unpublished{Aravkin11TRridr,
  author = {Aleksandr Y. Aravkin and Michael P. Friedlander and Felix J. Herrmann and Tristan
        van Leeuwen},
  title = {Robust inversion, dimensionality reduction, and randomized sampling},
  year = {2011},
notes = {TR-2011-13},  
address = {University of British Columbia, Vancouver},
  optmonth = {11/2011},
  abstract = {We consider a class of inverse problems in which the
                  forward model is the solution operator to linear
                  ODEs or PDEs. This class admits several
                  dimensionality-reduction techniques based on data
                  averaging or sampling, which are especially useful
                  for large-scale problems.  We survey these
                  approaches and their connection to stochastic
                  optimization.  The data-averaging approach is only
                  viable, however, for a least-squares misfit, which
                  is sensitive to outliers in the data and artifacts
                  unexplained by the forward model. This motivates us
                  to propose a robust formulation based on the
                  Student's t-distribution of the error.  We
                  demonstrate how the corresponding penalty function,
                  together with the sampling approach, can obtain good
                  results for a large-scale seismic inverse problem
                  with 50% corrupted data.},
  keywords = {SLIM,Optimization,Full-waveform inversion},
  url = {http://www.optimization-online.org/DB_FILE/2011/11/3243.pdf}
}

@unpublished{haber10TRemp,
  author = {Eldad Haber and Matthias Chung and Felix J. Herrmann},
  title = {An effective method for parameter estimation with PDE constraints
        with multiple right hand sides},
  institution = {UBC-Earth and Ocean Sciences Department},
  year = {2010},
  number = {TR-2010-4},
  abstract = {Many parameter estimation problems involve with a
                  parameter-dependent PDEs with multiple right hand
                  sides. The computational cost and memory
                  requirements of such problems increases linearly
                  with the number of right hand sides. For many
                  applications this is the main bottleneck of the
                  computation. In this paper we show that problems
                  with multiple right hand sides can be reformulated
                  as stochastic optimization problems that are much
                  cheaper to solve. We discuss the solution
                  methodology and use the direct current resistivity
                  and seismic tomography as model problems to show the
                  effectiveness of our approach.},
  keywords = {SLIM,Full-waveform inversion,Optimization},
  url = {http://slim.eos.ubc.ca/Publications/Public/Journals/Haber2010emp.pdf}
}

% Check with Michael whether this will be publsihed or stays as an technical report
@unpublished{vandenberg08gsv,
  author = {Ewout van den Berg and Mark Schmidt and Michael P. Friedlander and K.
	Murphy},
  title = {Group sparsity via linear-time projection},
institution = {UBC-Computer Science Department},
  year = {2008},
    number = {TR-2008-1},
  abstract = {We present an efficient spectral projected-gradient algorithm for
	optimization subject to a group one-norm constraint. Our approach
	is based on a novel linear-time algorithm for Euclidean projection
	onto the one- and group one-norm constraints. Numerical experiments
	on large data sets suggest that the proposed method is substantially
	more efficient and scalable than existing methods.},
  keywords = {SLIM,Optimization},
  url = {http://www.optimization-online.org/DB_FILE/2008/07/2056.pdf}
}

