% This file was created with JabRef 2.9.
% Encoding: MacRoman

%-----2019-----%

@UNPUBLISHED{herrmann2019NIPSliwcuc,
  author = {Felix J. Herrmann and Ali Siahkoohi and Gabrio Rizzuti},
  title = {Learned imaging with constraints and uncertainty quantification},
  year = {2019},
  abstract = {We outline new approaches to incorporate ideas from convolutional
networks into wave-based least-squares imaging. The aim is to combine
hand-crafted constraints with deep convolutional networks allowing us to
directly train a network capable of generating samples from the posterior. The main contributions include combination of weak deep priors with hard handcrafted constraints and a possible new way to sample the posterior.},
  keywords = {imaging, deep learning, uncertainty quantification, constraint, private},
  note = {Submitted to NIPS on September 9, 2019},
  url = {https://arxiv.org/pdf/1909.06473.pdf}
}

@UNPUBLISHED{witte2019TPDedas,
  author = {Philipp A. Witte and Mathias Louboutin and Henryk Modzelewski and Charles Jones and James Selvage and Felix J. Herrmann},
  title = {An Event-Driven Approach to Serverless Seismic Imaging in the Cloud},
  year = {2019},
  abstract = {Adapting the cloud for high-performance computing (HPC) is a
challenging task, as software for HPC applications hinges on fast network
connections and is sensitive to hardware failures. Using cloud infrastructure
to recreate conventional HPC clusters is therefore in many cases an
infeasible solution for migrating HPC applications to the cloud. As an
alternative to the generic lift and shift approach, we consider the specific
application of seismic imaging and demonstrate a serverless and event-driven
pproach for running large-scale instances of this problem in the cloud.
Instead of permanently running compute instances, our workflow is based on a
serverless architecture with high throughput batch computing and event-driven
computations, in which computational resources are only running as long as
they are utilized. We demonstrate that this approach is very flexible and
allows for resilient and nested levels of parallelization, including domain
decomposition for solving the underlying partial differential equations.
While the event-driven approach introduces some overhead as computational
resources are repeatedly restarted, it inherently provides resilience to
instance shut-downs and allows a significant reduction of cost by avoiding
idle instances, thus making the cloud a viable alternative to on-premise
clusters for large-scale seismic imaging.},
  keywords = {cloud, imaging, serverless, event-driven, lsrtm, private},
  note = {Submitted to IEEE Transactions on Parallel and Distributed Systems on August 20, 2019},
  url = {https://slim.gatech.edu/Publications/Private/Submitted/2019/witte2019TPDedas/witte2019TPDedas.html}
}

@UNPUBLISHED{kukreja2019PASCccd,
  author = {Navjot Kukreja and Jan Huckelheim and Mathias Louboutin and Kaiyuan Hou and Paul Hovland and Gerard Gorman},
  title = {Combining checkpointing and data compression to accelerate adjoint-based optimization problems},
  year = {2019},
  abstract = {Seismic inversion and imaging are adjoint-based optimization problems that processes up to terabytes of data, regularly exceeding the memory capacity of available computers. Data compression is an effective strategy to reduce this memory requirement by a certain factor, particularly if some loss in accuracy is acceptable. A popular alternative is checkpointing, where data is stored at selected points in time, and values at other times are recomputed as needed from the last stored state. This allows arbitrarily large adjoint computations with limited memory, at the cost of additional recomputations. In this paper we combine compression and checkpointing for the first time to compute a realistic seismic inversion. The combination of checkpointing and compression allows larger adjoint computations compared to using only compression, and reduces the recomputation overhead significantly compared to using only checkpointing.},
  keywords = {Adjoint-state, FD, checkpointing, compression, HPC, inverse problems, private},
  note = {Submitted to PASC19 on January 16, 2019},
  url = {https://slim.gatech.edu/Publications/Private/Submitted/2019/kukreja2019PASCccd/kukreja2019PASCccd.pdf}
}



%-----2018-----%

@UNPUBLISHED{luporini2018aap,
  author = {FABIO LUPORINI and MICHAEL LANGE and MATHIAS LOUBOUTIN and NAVJOT KUKREJA and JAN HUCKELHEIM and CHARLES YOUNT and PHILIPP A. WITTE and PAUL H. J. KELLY and GERARD J. GORMAN and FELIX J. HERRMANN},
  title = {Architecture and performance of Devito, a system for automated stencil computation},
  year = {2018},
  abstract = {Stencil computations are a key part of many high-performance computing applications, such as image processing, convolutional neural networks, and finite-difference solvers for partial differential equations. Devito is a framework capable of generating highly-optimized code given symbolic equations expressed in Python, specialized in, but not limited to, affine (stencil) codes. The lowering process – from mathematical equations down to C++ code – is
performed by the Devito compiler through a series of intermediate representations. Several performance optimizations are introduced, including advanced common sub-expressions elimination, tiling and parallelization. Some of these are obtained through well-established stencil optimizers, integrated in the back-end of the Devito compiler. The architecture of the Devito compiler, as well as the performance optimizations that are applied when generating code, are presented. The effectiveness of such performance optimizations is demonstrated using operators drawn from seismic imaging applications.},
  keywords = {Stencil, finite difference method, symbolic processing, structured grid, compiler, performance optimization, private},
  note = {Submitted to SIAM Journal on Scientific Computing on July 9, 2018.},
  url = {https://slim.gatech.edu/Publications/Private/Submitted/2018/luporini2018aap/luporini2018aap.pdf}
}

@UNPUBLISHED{witte2018alf,
  author = {Philipp A. Witte and Mathias Louboutin and Navjot Kukreja and Fabio Luporini and Michael Lange and Gerard J. Gorman and Felix J. Herrmann},
  title = {A large-scale framework for symbolic implementations of seismic inversion algorithms in Julia},
  year = {2018},
  abstract = {Writing software packages for seismic inversion is a very challenging task, since problems such as full-waveform inversion or least-squares imaging are both algorithmically and computationally demanding due to the large number of unknown parameters and the fact that we are propagating waves over many wavelengths. Software frameworks therefore need to combine both versatility and performance to provide geophysicists with the means and flexibility to implement complex algorithms that scale to exceedingly large 3D problems. Following these principles, we introduce the Julia Devito Inversion framework, an open-source software package in Julia for large-scale seismic modeling and inversion based on Devito, a domain-specific language compiler for automatic code generation. The framework consists of matrix-free linear operators for implementing seismic inversion algorithms that closely resembles the mathematical notation, a flexible resilient parallelization and an interface to Devito for generating optimized stencil code to solve the underlying wave equations. In comparison to many manually optimized industry codes written in low-level languages, our software is built on the idea of independent layers of abstractions and user interfaces with symbolic operators, making it possible to manage both the complexity of algorithms and performance optimizations, while preserving modularity, which allows for a level of expressiveness needed to formulate a broad range of wave-equation-based inversion problems. Through a series of numerical examples, we demonstrate that this allows users to implement algorithms for waveform inversion and imaging as simple Julia scripts that scale to large-scale 3D problems; thus providing a truly performant research and production framework.},
  keywords = {FWI, LSRTM, modeling, inversion, software, private},
  note = {Submitted to Geophysics on March 1, 2018.},
  url = {https://slim.gatech.edu/Publications/Private/Submitted/2018/witte2018alf/witte2018alf.html}
}

@UNPUBLISHED{witte2018cls,
  author = {Philipp A. Witte and Mathias Louboutin and Fabio Luporini and Gerard J. Gorman and Felix J. Herrmann},
  title = {Compressive least-squares migration with on-the-fly Fourier transforms},
  year = {2018},
  abstract = {Least-squares reverse-time migration is a powerful approach for true amplitude seismic imaging of complex geological structures, but the successful application of this method is currently hindered by its enormous computational cost, as well as high memory requirements for computing the gradient of the objective function. We tackle these problems by introducing an algorithm for low-cost sparsity-promoting least-squares migration using on-the-fly Fourier transforms. We formulate the least-squares migration objective function in the frequency domain and compute gradients for randomized subsets of shot records and frequencies, thus significantly reducing data movement and the number of overall wave equations solves. By using on-the-fly Fourier transforms, we can compute an arbitrary number of monochromatic frequency-domain wavefields with a time-domain modeling code, instead of having to solve individual Helmholtz equations for each frequency, which quickly becomes computationally infeasible when moving to high frequencies. Our numerical examples demonstrate that compressive imaging with on-the-fly Fourier transforms provides a fast and memory-efficient alternative to time-domain imaging with optimal checkpointing, whose memory requirements for a fixed background model and source wavelet is independent of the number of time steps. Instead, memory and additional computational cost grow with the number of frequencies and determine the amount of subsampling artifacts and crosstalk. In contrast to optimal checkpointing, this offers the possibility to trade both memory and computational cost for image quality or a larger number of iterations and is advantageous in new computing environments such as the cloud, where compute is often cheaper than memory and data movement.},
  keywords = {least squares migration, Fourier, sparsity-promotion, private},
  note = {Submitted to Geophysics on June 28, 2018.},
  url = {https://slim.gatech.edu/Publications/Private/Submitted/2018/witte2018cls/witte2018cls.html}
}