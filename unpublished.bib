% This file was created with JabRef 2.9.
% Encoding: MacRoman

%-----2016-----%

@UNPUBLISHED{oghenekohwo2016GEOPctl,
  author = {Felix Oghenekohwo and Haneet Wason and Ernie Esser and Felix J. Herrmann},
  title = {Cheap time lapse with distributed Compressive Sensing---exploiting common information among the vintages},
  year = {2016},
  abstract = {Time-lapse seismic has been a powerful, but technically
                  challenging, practice for monitoring changes due to
                  production. Aside from physical changes amongst
                  time-lapse surveys---such as noise and variations in
                  water column velocities, over which we have limited
                  control---executing colocated densely sampled
                  baseline and monitor surveys with high degrees of
                  replicability are expensive propositions. We
                  demonstrate that under "ideal" circumstances, where
                  the surveys are in principle replicable,
                  high-quality pre-stack data can be obtained from
                  cheap randomized subsampled measurements that are
                  observed from non-replicated surveys. Aside from the
                  obvious economic advantage of removing reliance on
                  replication during acquisition, we find that the
                  recovered densely sampled pre-stack baseline and
                  monitor data actually improve significantly when the
                  acquisitions are not replicated. We achieve this
                  result by using the fact that different time-lapse
                  data share information and that non-replicated
                  surveys can add information when pre-stack data are
                  recovered jointly. Whenever the time-lapse data
                  exhibit joint structure---i.e., are compressible in
                  some transform domain and share
                  information---sparsity-promoting recovery of the
                  "common component", and "innovations", with respect
                  to this common component, outperforms independent
                  recovery of both the pre-stack baseline and monitor
                  data. The recovered time-lapse data are of high
                  enough quality to serve as input to extract
                  post-stack attributes used to compute time-lapse
                  differences. Without joint recovery, artifacts, due
                  to the randomized subsampling, lead to a
                  deterioration of the degree of repeatability of the
                  time-lapse data. We support our claims by carrying
                  out experiments that collect reliable statistics
                  from thousands of repeated experiments. We also
                  confirm that high degrees of repeatability are
                  achievable for an ocean-bottom cable survey acquired
                  with time-jittered continuous recording.},
  keywords = {acquisition, time-lapse seismic, marine, random sampling, joint recovery method, private},
  note = {to be submitted to Geophysics},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2016/oghenekohwo2016GEOPctl/oghenekohwo2016GEOPctl.html}
}


@UNPUBLISHED{wason2016GEOPctl,
  author = {Haneet Wason and Felix Oghenekohwo and Felix J. Herrmann},
  title = {Cheap time lapse with distributed Compressive Sensing---impact on repeatability},
  year = {2016},
  keywords = {marine acquisition, time-lapse seismic, off-the-grid recovery, random sampling, joint recovery method, optimization, private},
  note = {to be submitted to Geophysics}
}


%-----2015-----%

@UNPUBLISHED{bougher2015CSEGust,
  author = {Ben B. Bougher and Felix J. Herrmann},
  title = {Using the scattering transform to predict stratigraphic units from well logs},
  year = {2015},
  abstract = {Much of geophysical interpretation relies on trained
                  pattern recognition of signals and images, a
                  workflow that can be modeled by supervised machine
                  learning. A challenge of supervised learning is
                  determining a physically meaningful feature set that
                  can successfully classify the data. Defined by a
                  network of cascading wavelets, the scattering
                  transform provides a non-linear multiscale analysis
                  that has deep connections to the fractal statistics
                  of the signal. Interestingly, the scattering
                  transform takes the form of a pre-trained
                  convolutional neural network. This paper uses the
                  scattering transform to extract features from well
                  logs in order to train a classifier that can predict
                  stratigraphic units. The methodology is tested on
                  interpreted well logs from Trenton-Black River
                  project and initial results are presented.},
  keywords = {machine learning, scattering transform, well logs, private},
  note = {Submitted to CSEG Recorder on November 16.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2015/bougher2015CSEGust/bougher2015CSEGust.html}
}


@UNPUBLISHED{lopez2015IEEEogl,
  author = {Oscar Lopez and Rajiv Kumar and Ozgur Yilmaz and Felix J. Herrmann},
  title = {Off the grid low rank matrix recovery},
  year = {2015},
  abstract = {Matrix sensing and matrix completion problems capitalize
                  on the knowledge that a data matrix of interest
                  exhibits low rank properties. This low dimensional
                  structure often arises because the data matrix is
                  obtained by sampling a smooth function on a regular
                  (or structured) grid. However, in many practical
                  situations the measurements are taken on an
                  irregular grid (that is completely known). This
                  results in an ``unstructured data matrix'' that is
                  less fit for the low rank model in comparison to its
                  regular counterpart. In this paper we propose and
                  analyze a modified low rank matrix recovery workflow
                  that admits unstructured observations. By
                  incorporating a regularization operator which
                  accurately maps structured data to unstructured
                  data, into the nuclear norm minimization problem, we
                  are able to compensate for data irregularity.
                  Furthermore, by construction our formulation yields
                  output that is supported on a structured grid, so
                  that in effect we also regularize the data
                  matrix. We establish recovery error bounds for our
                  methodology and offer several matrix sensing and
                  matrix completion numerical experiments including
                  applications to frugal seismic data acquisition to
                  demonstrate the potential of the approach.},
  keywords = {matrix sensing, matrix completion, nuclear norm relaxation, NFFT, seismic trace interpolation, simultaneous source separation, private},
  note = {Submitted to the IEEE Journal of Selected Topics in Signal Processing on July 30.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2015/lopez2015IEEEogl/lopez2015IEEEogl.pdf}
}


@UNPUBLISHED{tu2015GJIsem,
  author = {Ning Tu and Aleksandr Y. Aravkin and Tristan van Leeuwen and Tim T.Y. Lin and Felix J. Herrmann},
  title = {Source estimation with surface-related multiples---fast ambiguity-resolved seismic imaging},
  year = {2015},
  abstract = {We address the problem of obtaining a reliable seismic
                  image without prior knowledge of the source wavelet,
                  especially from data that contain strong
                  surface-related multiples. Conventional reverse-time
                  migration requires prior knowledge of the source
                  wavelet, which is either technically or
                  computationally challenging to accurately determine;
                  inaccurate estimates of the source wavelet can
                  result in seriously degraded reverse-time migrated
                  images, and therefore wrong geological
                  interpretations. To solve this problem, we present a
                  "wavelet-free" imaging procedure that simultaneously
                  inverts for the source wavelet and the seismic
                  image, by tightly integrating source estimation into
                  a fast least-squares imaging framework, namely
                  compressive imaging, given a reasonably accurate
                  background velocity model. However, this joint
                  inversion problem is difficult to solve as it is
                  plagued with local minima and the ambiguity with
                  respect to amplitude scalings, because of the
                  multiplicative, and therefore nonlinear, appearance
                  of the source wavelet in the otherwise linear
                  formalism. We have found a way to solve this
                  nonlinear joint-inversion problem using a technique
                  called variable projection, and a way to overcome
                  the scaling ambiguity by including surface-related
                  multiples in our imaging procedure following recent
                  developments in surface-related multiple prediction
                  by sparse inversion. As a result, we obtain without
                  prior knowledge of the source wavelet
                  high-resolution seismic images, comparable in
                  quality to images obtained assuming the true source
                  wavelet is known. By leveraging the computationally
                  efficient compressive-imaging methodology, these
                  results are obtained at affordable computational
                  costs compared with conventional processing work
                  flows that include surface-related multiple removal
                  and reverse-time migration.},
  keywords = {inverse theory, time series analysis, computational seismology, wave propagation, free surface, multiples, seismic imaging, private},
  note = {Submitted to Geophysical Journal International on May 14. Revision 1 submitted on November 29.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2015/tu2015GJIsem/tu2015GJIsem.html}
}


@UNPUBLISHED{vanleeuwen2015GPWEMVA,
  author = {Tristan van Leeuwen and Rajiv Kumar and Felix J. Herrmann},
  title = {Enabling affordable omnidirectional subsurface extended image volumes via probing},
  year = {2015},
  abstract = {Image gathers as a function of subsurface offset are an
                  important tool for the inference of rock properties
                  and velocity analysis in areas of complex
                  geology. Traditionally, these gathers are thought of
                  as multidimensional correlations of the source and
                  receiver wavefields. The bottleneck in computing
                  these gathers lies in the fact that one needs to
                  store, compute, and correlate these wavefields for
                  all shots in order to obtain the desired image
                  gathers. Therefore, the image gathers are typically
                  only computed for a limited number of subsurface
                  points and for a limited range of subsurface
                  offsets, which may cause problems in complex
                  geological areas with large geologic dips. We
                  overcome increasing computational and storage costs
                  of extended image volumes by introducing a
                  formulation that avoids explicit storage and removes
                  the customary and expensive loop over shots, found
                  in conventional extended imaging. As a result, we
                  end up with a matrix-vector formulation from which
                  different image gathers can be formed and with which
                  amplitude-versus-angle and wave-equation migration
                  velocity analyses can be performed without requiring
                  prior information on the geologic dips. Aside from
                  demonstrating the formation of two-way extended
                  image gathers for different purposes and at greatly
                  reduced costs, we also present a new approach to
                  conduct automatic wave-equation based
                  migration-velocity analysis. Instead of focussing in
                  particular offset directions and preselected subsets
                  of subsurface points, our method focuses every
                  subsurface point for all subsurface offset
                  directions using a randomized probing technique. As
                  a consequence, we obtain good velocity models at low
                  cost for complex models without the need to provide
                  information on the geologic dips.},
  keywords = {migration velocity analysis, AVA, stochastic optimization, private},
  note = {Submitted to Geophysical Prospecting on May 6. Revision 1 submitted on November 30.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2015/vanleeuwen2015GPWEMVA/vanleeuwen2015GPWEMVA.pdf}
}

