% This file was created with JabRef 2.9.
% Encoding: MacRoman

%-----2015-----%

@UNPUBLISHED{bougher2015CSEGust,
  author = {Ben B. Bougher and Felix J. Herrmann},
  title = {Using the scattering transform to predict stratigraphic units from well logs},
  year = {2015},
  abstract = {Much of geophysical interpretation relies on trained
                  pattern recognition of signals and images, a
                  workflow that can be modeled by supervised machine
                  learning. A challenge of supervised learning is
                  determining a physically meaningful feature set that
                  can successfully classify the data. Defined by a
                  network of cascading wavelets, the scattering
                  transform provides a non-linear multiscale analysis
                  that has deep connections to the fractal statistics
                  of the signal. Interestingly, the scattering
                  transform takes the form of a pre-trained
                  convolutional neural network. This paper uses the
                  scattering transform to extract features from well
                  logs in order to train a classifier that can predict
                  stratigraphic units. The methodology is tested on
                  interpreted well logs from Trenton-Black River
                  project and initial results are presented.},
  keywords = {machine learning, scattering transform, well logs, private},
  note = {Submitted to CSEG Recorder on November 16.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2015/bougher2015CSEGust/bougher2015CSEGust.html}
}


@UNPUBLISHED{lopez2015IEEEogl,
  author = {Oscar Lopez and Rajiv Kumar and Ozgur Yilmaz and Felix J. Herrmann},
  title = {Off the grid low rank matrix recovery},
  year = {2015},
  abstract = {Matrix sensing and matrix completion problems capitalize
                  on the knowledge that a data matrix of interest
                  exhibits low rank properties. This low dimensional
                  structure often arises because the data matrix is
                  obtained by sampling a smooth function on a regular
                  (or structured) grid. However, in many practical
                  situations the measurements are taken on an
                  irregular grid (that is completely known). This
                  results in an ``unstructured data matrix'' that is
                  less fit for the low rank model in comparison to its
                  regular counterpart. In this paper we propose and
                  analyze a modified low rank matrix recovery workflow
                  that admits unstructured observations. By
                  incorporating a regularization operator which
                  accurately maps structured data to unstructured
                  data, into the nuclear norm minimization problem, we
                  are able to compensate for data irregularity.
                  Furthermore, by construction our formulation yields
                  output that is supported on a structured grid, so
                  that in effect we also regularize the data
                  matrix. We establish recovery error bounds for our
                  methodology and offer several matrix sensing and
                  matrix completion numerical experiments including
                  applications to frugal seismic data acquisition to
                  demonstrate the potential of the approach.},
  keywords = {matrix sensing, matrix completion, nuclear norm relaxation, NFFT, seismic trace interpolation, simultaneous source separation, private},
  note = {Submitted to the IEEE Journal of Selected Topics in Signal Processing on July 30.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2015/lopez2015IEEEogl/lopez2015IEEEogl.pdf}
}


@UNPUBLISHED{tu2015GJIsem,
  author = {Ning Tu and Aleksandr Y. Aravkin and Tristan van Leeuwen and Tim T.Y. Lin and Felix J. Herrmann},
  title = {Source estimation with surface-related multiples---fast ambiguity-resolved seismic imaging},
  year = {2015},
  abstract = {We address the problem of obtaining a reliable seismic
                  image without prior knowledge of the source wavelet,
                  especially from data that contain strong
                  surface-related multiples. Conventional reverse-time
                  migration requires prior knowledge of the source
                  wavelet, which is either technically or
                  computationally challenging to accurately determine;
                  inaccurate estimates of the source wavelet can
                  result in seriously degraded reverse-time migrated
                  images, and therefore wrong geological
                  interpretations. To solve this problem, we present a
                  "wavelet-free" imaging procedure that simultaneously
                  inverts for the source wavelet and the seismic
                  image, by tightly integrating source estimation into
                  a fast least-squares imaging framework, namely
                  compressive imaging, given a reasonably accurate
                  background velocity model. However, this joint
                  inversion problem is difficult to solve as it is
                  plagued with local minima and the ambiguity with
                  respect to amplitude scalings, because of the
                  multiplicative, and therefore nonlinear, appearance
                  of the source wavelet in the otherwise linear
                  formalism. We have found a way to solve this
                  nonlinear joint-inversion problem using a technique
                  called variable projection, and a way to overcome
                  the scaling ambiguity by including surface-related
                  multiples in our imaging procedure following recent
                  developments in surface-related multiple prediction
                  by sparse inversion. As a result, we obtain without
                  prior knowledge of the source wavelet
                  high-resolution seismic images, comparable in
                  quality to images obtained assuming the true source
                  wavelet is known. By leveraging the computationally
                  efficient compressive-imaging methodology, these
                  results are obtained at affordable computational
                  costs compared with conventional processing work
                  flows that include surface-related multiple removal
                  and reverse-time migration.},
  keywords = {inverse theory, time series analysis, computational seismology, wave propagation, free surface, multiples, seismic imaging, private},
  note = {Submitted to Geophysical Journal International on May 14. Revision 1 submitted on November 29.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2015/tu2015GJIsem/tu2015GJIsem.html}
}


@UNPUBLISHED{vanleeuwen2015GPWEMVA,
  author = {Tristan van Leeuwen and Rajiv Kumar and Felix J. Herrmann},
  title = {Enabling affordable omnidirectional subsurface extended image volumes via probing},
  year = {2015},
  abstract = {Image gathers as a function of subsurface offset are an
                  important tool for the inference of rock properties
                  and velocity analysis in areas of complex
                  geology. Traditionally, these gathers are thought of
                  as multidimensional correlations of the source and
                  receiver wavefields. The bottleneck in computing
                  these gathers lies in the fact that one needs to
                  store, compute, and correlate these wavefields for
                  all shots in order to obtain the desired image
                  gathers. Therefore, the image gathers are typically
                  only computed for a limited number of subsurface
                  points and for a limited range of subsurface
                  offsets, which may cause problems in complex
                  geological areas with large geologic dips. We
                  overcome increasing computational and storage costs
                  of extended image volumes by introducing a
                  formulation that avoids explicit storage and removes
                  the customary and expensive loop over shots, found
                  in conventional extended imaging. As a result, we
                  end up with a matrix-vector formulation from which
                  different image gathers can be formed and with which
                  amplitude-versus-angle and wave-equation migration
                  velocity analyses can be performed without requiring
                  prior information on the geologic dips. Aside from
                  demonstrating the formation of two-way extended
                  image gathers for different purposes and at greatly
                  reduced costs, we also present a new approach to
                  conduct automatic wave-equation based
                  migration-velocity analysis. Instead of focussing in
                  particular offset directions and preselected subsets
                  of subsurface points, our method focuses every
                  subsurface point for all subsurface offset
                  directions using a randomized probing technique. As
                  a consequence, we obtain good velocity models at low
                  cost for complex models without the need to provide
                  information on the geologic dips.},
  keywords = {migration velocity analysis, AVA, stochastic optimization, private},
  note = {Submitted to Geophysical Prospecting on May 6. Revision 1 submitted on November 30.},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2015/vanleeuwen2015GPWEMVA/vanleeuwen2015GPWEMVA.pdf}
}


%-----2014-----%

@UNPUBLISHED{oghenekohwo2014GEOPfrt,
  author = {Felix Oghenekohwo and Haneet Wason and Ernie Esser and Felix J. Herrmann},
  title = {Compressive 4D—economic time-lapse seismic with randomized subsampling and joint recovery},
  year = {2014},
  month = {10},
  abstract = {The current paradigm of time-lapse seismic relies on
                  dense sampling and repeatability amongst the
                  baseline and the monitor surveys. Recent results in
                  distributed compressive sensing allow us to come up
                  with a new economic sampling paradigm where the
                  vintages and time-lapse difference are recovered
                  from incomplete data. The combination of randomized
                  sampling, signal structure and correlations among
                  the vintages underlies this approach. In a somewhat
                  idealized setting where effects such as difference
                  in currents are ignored, and where we do not have
                  access to dense samplings of the baseline and/or
                  monitor surveys, we can get high quality recovery of
                  these vintages and time-lapse difference when there
                  is a small “overlap” in the surveys—i.e., where the
                  random samplings have partial statistical
                  dependence. Specifically, we find that the quality
                  of the vintages improves for decreasing overlap in
                  the surveys while the converse is true for the
                  time-lapse difference. Our setting differs from
                  conventional time-lapse acquisition because we do
                  not have access to dense samplings. Surveys with
                  partial overlapping randomized samplings lead to the
                  best trade-off between the recovery quality of the
                  vintages and the time-lapse signal. We confirm this
                  by a series of experiments.},
  keywords = {acquistion, time-lapse, marine, sampling, random, joint recovery method, private},
  note = {Submitted revision 1 to Geophysics on October 22, 2014},
  url = {https://www.slim.eos.ubc.ca/Publications/Private/Submitted/2014/oghenekohwo2014GEOPfrt/oghenekohwo2014GEOPfrt.html}
}

